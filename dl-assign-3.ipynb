{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T17:07:36.206908Z",
     "iopub.status.busy": "2025-05-20T17:07:36.206683Z",
     "iopub.status.idle": "2025-05-20T17:07:51.548688Z",
     "shell.execute_reply": "2025-05-20T17:07:51.548092Z",
     "shell.execute_reply.started": "2025-05-20T17:07:36.206887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 17:07:38.834771: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747760859.090301      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747760859.161502      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, RNN, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:07:51.549835Z",
     "iopub.status.busy": "2025-05-20T17:07:51.549391Z",
     "iopub.status.idle": "2025-05-20T17:08:00.299745Z",
     "shell.execute_reply": "2025-05-20T17:08:00.299181Z",
     "shell.execute_reply.started": "2025-05-20T17:07:51.549809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmm21b044\u001b[0m (\u001b[33mmm21b044-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "wandb.login(key='e030007b097df00d9a751748294abc8440f932b1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T14:01:58.565913Z",
     "iopub.status.busy": "2025-05-20T14:01:58.565630Z",
     "iopub.status.idle": "2025-05-20T14:02:54.916092Z",
     "shell.execute_reply": "2025-05-20T14:02:54.915527Z",
     "shell.execute_reply.started": "2025-05-20T14:01:58.565892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140159-r1yo9564</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/r1yo9564' target=\"_blank\">vanilla_lstm_run_q1</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/r1yo9564' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/r1yo9564</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747749727.720180      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1747749727.720823      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate total multiplications (encoder + decoder): 2,260,992\n",
      "Total trainable parameters: 201,869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ enc_lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]     │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dec_lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ enc_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],      │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │ enc_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │ dec_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ decoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m1,728\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m832\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ enc_lstm_0 (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │         \u001b[38;5;34m98,816\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]     │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dec_lstm_0 (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),    │         \u001b[38;5;34m98,816\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ enc_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],      │\n",
       "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │ enc_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)       │          \u001b[38;5;34m1,677\u001b[0m │ dec_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,869</span> (788.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,869\u001b[0m (788.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,869</span> (788.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,869\u001b[0m (788.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747749734.614468     131 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.7907 - loss: 0.6139 - val_accuracy: 0.8282 - val_loss: 0.3884\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.4008 - val_accuracy: 0.8293 - val_loss: 0.3774\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8283 - loss: 0.3912 - val_accuracy: 0.8322 - val_loss: 0.3763\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.3900 - val_accuracy: 0.8346 - val_loss: 0.3753\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.3864 - val_accuracy: 0.8374 - val_loss: 0.3713\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 0.3810 - val_accuracy: 0.8403 - val_loss: 0.3711\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8407 - loss: 0.3774 - val_accuracy: 0.8440 - val_loss: 0.3640\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 0.3755 - val_accuracy: 0.8440 - val_loss: 0.3626\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▆▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_trainable_params</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▁▃▄▅▆██</td></tr><tr><td>val_loss</td><td>█▅▅▄▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84121</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.36256</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.37412</td></tr><tr><td>total_flops</td><td>2260992</td></tr><tr><td>total_trainable_params</td><td>201869</td></tr><tr><td>val_accuracy</td><td>0.84397</td></tr><tr><td>val_loss</td><td>0.36256</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vanilla_lstm_run_q1</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/r1yo9564' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/r1yo9564</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_140159-r1yo9564/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['latin', 'native'])\n",
    "    df = df.dropna()\n",
    "    df['latin'] = df['latin'].astype(str)\n",
    "    df['native'] = df['native'].astype(str)\n",
    "    return df\n",
    "\n",
    "def load_dakshina_dataset(language_code='hi', base_dir='/kaggle/input/dak-data/dakshina_dataset_v1.0'):\n",
    "    path = os.path.join(base_dir, language_code, 'lexicons')\n",
    "    return (\n",
    "        load_data(os.path.join(path, f'{language_code}.translit.sampled.train.tsv')),\n",
    "        load_data(os.path.join(path, f'{language_code}.translit.sampled.dev.tsv')),\n",
    "        load_data(os.path.join(path, f'{language_code}.translit.sampled.test.tsv')),\n",
    "    )\n",
    "\n",
    "train_data, val_data, test_data = load_dakshina_dataset()\n",
    "\n",
    "# ─── 1) Extract raw texts ─────────────────────────────────────────\n",
    "input_texts  = train_data['latin'].tolist()\n",
    "target_texts = ['\\t' + t + '\\n' for t in train_data['native'].tolist()]\n",
    "\n",
    "val_input_texts  = val_data['latin'].tolist()\n",
    "val_target_texts = ['\\t' + t + '\\n' for t in val_data['native'].tolist()]\n",
    "\n",
    "input_tokenizer = Tokenizer(char_level=True, oov_token=None)\n",
    "input_tokenizer.fit_on_texts(input_texts + val_input_texts)\n",
    "\n",
    "target_tokenizer = Tokenizer(char_level=True, oov_token=None)\n",
    "target_tokenizer.fit_on_texts(target_texts + val_target_texts)\n",
    "\n",
    "# ─── 3) Convert texts → integer sequences + pad to max lengths ───\n",
    "# Compute max lengths\n",
    "max_in  = max(len(txt) for txt in input_texts + val_input_texts)\n",
    "max_out = max(len(txt) for txt in target_texts + val_target_texts)\n",
    "\n",
    "# Integer‑encode + pad\n",
    "encoder_input_train = pad_sequences(\n",
    "    input_tokenizer.texts_to_sequences(input_texts),\n",
    "    maxlen=max_in,\n",
    "    padding='post'\n",
    ")\n",
    "decoder_input_train = pad_sequences(\n",
    "    target_tokenizer.texts_to_sequences(target_texts),\n",
    "    maxlen=max_out,\n",
    "    padding='post'\n",
    ")\n",
    "# decoder targets are the decoder inputs shifted left by one\n",
    "decoder_target_train = np.array(decoder_input_train)[:, 1:]\n",
    "decoder_input_train   = np.array(decoder_input_train)[:, :-1]\n",
    "\n",
    "# Do the same for validation set\n",
    "encoder_input_val = pad_sequences(\n",
    "    input_tokenizer.texts_to_sequences(val_input_texts),\n",
    "    maxlen=max_in,\n",
    "    padding='post'\n",
    ")\n",
    "decoder_input_val = pad_sequences(\n",
    "    target_tokenizer.texts_to_sequences(val_target_texts),\n",
    "    maxlen=max_out,\n",
    "    padding='post'\n",
    ")\n",
    "decoder_target_val = np.array(decoder_input_val)[:, 1:]\n",
    "decoder_input_val   = np.array(decoder_input_val)[:, :-1]\n",
    "\n",
    "# Make sure any previous wandb runs are finished\n",
    "try:\n",
    "    wandb.finish()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize wandb with proper error handling\n",
    "try:\n",
    "    wandb.init(\n",
    "        project=\"DA_seq2seq_transliteration\",\n",
    "        name=\"vanilla_lstm_run_q1\",\n",
    "        # Removed reinit=True to prevent connection issues\n",
    "        config={\n",
    "            \"model_type\": \"vanilla\",\n",
    "            \"cell_type\": \"LSTM\",\n",
    "            \"embedding_dim\": 64,\n",
    "            \"hidden_dim\": 128,\n",
    "            \"dropout_rate\": 0.2,\n",
    "            \"batch_size\": 64,\n",
    "            \"epochs\": 10,\n",
    "            \"input_vocab_size\": len(input_tokenizer.word_index) + 1,\n",
    "            \"target_vocab_size\": len(target_tokenizer.word_index) + 1,\n",
    "            \"max_input_length\": max_in,\n",
    "            \"max_target_length\": max_out,\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"sparse_categorical_crossentropy\",\n",
    "            \"dataset\": \"dakshina_hi\"\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize wandb: {e}\")\n",
    "    # Create a dummy wandb to avoid errors in the code\n",
    "    class DummyWandb:\n",
    "        def log(self, *args, **kwargs):\n",
    "            pass\n",
    "        def config(self, *args, **kwargs):\n",
    "            return type('obj', (object,), {\n",
    "                'embedding_dim': 64,\n",
    "                'hidden_dim': 128,\n",
    "                'get': lambda s, k, d: d\n",
    "            })\n",
    "    wandb = DummyWandb()\n",
    "\n",
    "class VanillaSeq2Seq:\n",
    "    def __init__(self,\n",
    "                 input_vocab_size,\n",
    "                 target_vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 cell_type='LSTM',\n",
    "                 dropout_rate=0.2,\n",
    "                 num_encoder_layers=1,\n",
    "                 num_decoder_layers=1):\n",
    "        self.input_vocab_size  = input_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.embedding_dim     = embedding_dim\n",
    "        self.hidden_dim        = hidden_dim\n",
    "        self.cell_type         = cell_type\n",
    "        self.dropout_rate      = dropout_rate\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _rnn_layer(self, return_sequences, return_state):\n",
    "        \"\"\"Factory for one RNN/LSTM/GRU layer.\"\"\"\n",
    "        if self.cell_type == 'LSTM':\n",
    "            return LSTM(self.hidden_dim,\n",
    "                        return_sequences=return_sequences,\n",
    "                        return_state=return_state)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            return GRU(self.hidden_dim,\n",
    "                       return_sequences=return_sequences,\n",
    "                       return_state=return_state)\n",
    "        else:\n",
    "            return RNN(self.hidden_dim,\n",
    "                       return_sequences=return_sequences,\n",
    "                       return_state=return_state)\n",
    "\n",
    "    def _build_model(self):\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
    "        x = Embedding(self.input_vocab_size, self.embedding_dim)(encoder_inputs)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Stack encoder layers\n",
    "        encoder_states = []\n",
    "        for i in range(self.num_encoder_layers):\n",
    "            # last encoder layer returns only state, earlier ones return sequences\n",
    "            rs = (i < self.num_encoder_layers - 1)\n",
    "            if self.cell_type == 'LSTM':\n",
    "                x, state_h, state_c = LSTM(\n",
    "                    self.hidden_dim,\n",
    "                    return_sequences=rs,\n",
    "                    return_state=True,\n",
    "                    name=f'enc_lstm_{i}'\n",
    "                )(x)\n",
    "                encoder_states = [state_h, state_c]\n",
    "            else:\n",
    "                x, state_h = self._rnn_layer(\n",
    "                    return_sequences=rs,\n",
    "                    return_state=True\n",
    "                )(x)\n",
    "                encoder_states = [state_h]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "        y = Embedding(self.target_vocab_size, self.embedding_dim)(decoder_inputs)\n",
    "        y = Dropout(self.dropout_rate)(y)\n",
    "\n",
    "        # Stack decoder layers\n",
    "        for i in range(self.num_decoder_layers):\n",
    "            rs = True  # decoder always returns sequences for all but we only care about final dense\n",
    "            if self.cell_type == 'LSTM':\n",
    "                # feed initial_state only to the first decoder layer\n",
    "                init_st = encoder_states if i == 0 else None\n",
    "                y, dh, dc = LSTM(\n",
    "                    self.hidden_dim,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    name=f'dec_lstm_{i}'\n",
    "                )(y, initial_state=init_st) if init_st else LSTM(\n",
    "                    self.hidden_dim,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    name=f'dec_lstm_{i}'\n",
    "                )(y)\n",
    "            else:\n",
    "                init_st = encoder_states if i == 0 else None\n",
    "                y, dh = self._rnn_layer(\n",
    "                    return_sequences=True,\n",
    "                    return_state=True\n",
    "                )(y, initial_state=init_st) if init_st else self._rnn_layer(\n",
    "                    return_sequences=True,\n",
    "                    return_state=True\n",
    "                )(y)\n",
    "\n",
    "        # Final projection\n",
    "        outputs = Dense(self.target_vocab_size, activation='softmax')(y)\n",
    "        return Model([encoder_inputs, decoder_inputs], outputs)\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='sparse_categorical_crossentropy'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    def fit(self, train_data, val_data, batch_size=64, epochs=8, callbacks=None):\n",
    "        return self.model.fit(\n",
    "            [train_data['encoder_input'], train_data['decoder_input']],\n",
    "            np.expand_dims(train_data['decoder_target'], -1),\n",
    "            validation_data=(\n",
    "                [val_data['encoder_input'], val_data['decoder_input']],\n",
    "                np.expand_dims(val_data['decoder_target'], -1)\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "model = VanillaSeq2Seq(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    embedding_dim=64,\n",
    "    hidden_dim=128,\n",
    "    cell_type='LSTM',\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "model.compile()\n",
    "\n",
    "# Modified wandb callback with error handling\n",
    "try:\n",
    "    wandb_callback = WandbCallback(\n",
    "        log_model=False,           # no wandb artifact\n",
    "        save_graph=False,          # don't try to render graph\n",
    "        save_model=False           # ✅ disables all auto saving\n",
    "    )\n",
    "    callbacks = [wandb_callback]\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize WandbCallback: {e}\")\n",
    "    callbacks = []\n",
    "\n",
    "# Use try-except for wandb config access\n",
    "try:\n",
    "    D = wandb.config.embedding_dim\n",
    "    H = wandb.config.hidden_dim\n",
    "    L_e = wandb.config.get(\"num_encoder_layers\", 1)\n",
    "    L_d = wandb.config.get(\"num_decoder_layers\", 1)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to access wandb config: {e}\")\n",
    "    D = 64  # Default values\n",
    "    H = 128\n",
    "    L_e = 1\n",
    "    L_d = 1\n",
    "\n",
    "T_enc = encoder_input_train.shape[1]\n",
    "T_dec = decoder_input_train.shape[1]\n",
    "\n",
    "flops_per_step = 4 * (H * D + H * H)\n",
    "\n",
    "# 4) Total ops over all layers & timesteps\n",
    "total_enc_flops = L_e * T_enc * flops_per_step\n",
    "total_dec_flops = L_d * T_dec * flops_per_step\n",
    "total_flops = total_enc_flops + total_dec_flops\n",
    "\n",
    "print(f\"Approximate total multiplications (encoder + decoder): {total_flops:,}\")\n",
    "\n",
    "total_params = model.model.count_params()\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "model.model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    train_data={\n",
    "        'encoder_input': encoder_input_train,\n",
    "        'decoder_input': decoder_input_train,\n",
    "        'decoder_target': decoder_target_train\n",
    "    },\n",
    "    val_data={\n",
    "        'encoder_input': encoder_input_val,\n",
    "        'decoder_input': decoder_input_val,\n",
    "        'decoder_target': decoder_target_val\n",
    "    },\n",
    "    batch_size=64,\n",
    "    epochs=8,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Log metrics to wandb with error handling\n",
    "try:\n",
    "    wandb.log({\n",
    "        \"total_flops\": total_flops,\n",
    "        \"total_trainable_params\": total_params\n",
    "    })\n",
    "    # Properly close the wandb run\n",
    "    wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to log to wandb: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T14:02:54.917711Z",
     "iopub.status.busy": "2025-05-20T14:02:54.917424Z",
     "iopub.status.idle": "2025-05-20T14:02:54.922176Z",
     "shell.execute_reply": "2025-05-20T14:02:54.921526Z",
     "shell.execute_reply.started": "2025-05-20T14:02:54.917694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T14:02:54.923169Z",
     "iopub.status.busy": "2025-05-20T14:02:54.922985Z",
     "iopub.status.idle": "2025-05-20T14:02:55.248884Z",
     "shell.execute_reply": "2025-05-20T14:02:55.247994Z",
     "shell.execute_reply.started": "2025-05-20T14:02:54.923155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the Dakshina dataset (Hindi as an example)\n",
    "# You can change 'hi' to the language of your choice\n",
    "def load_dakshina_data(lang='hi'):\n",
    "    base_path = f'/kaggle/input/dak-data/dakshina_dataset_v1.0/{lang}/lexicons/'\n",
    "    \n",
    "    # Load train, dev, test sets\n",
    "    train_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.train.tsv', sep='\\t', \n",
    "                             header=None, names=['latin', 'native', 'class'])\n",
    "    val_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.dev.tsv', sep='\\t', \n",
    "                           header=None, names=['latin', 'native', 'class'])\n",
    "    test_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.test.tsv', sep='\\t', \n",
    "                            header=None, names=['latin', 'native', 'class'])\n",
    "\n",
    "    # Drop any rows with missing values\n",
    "    train_data = train_data.dropna().astype(str)\n",
    "    val_data   = val_data.dropna().astype(str)\n",
    "    test_data  = test_data.dropna().astype(str)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Process data and create sequences\n",
    "def process_data(train_data, val_data):\n",
    "    # Extract texts\n",
    "    input_texts = train_data['latin'].tolist()\n",
    "    target_texts = ['\\t' + t + '\\n' for t in train_data['native'].tolist()]\n",
    "    \n",
    "    val_input_texts = val_data['latin'].tolist()\n",
    "    val_target_texts = ['\\t' + t + '\\n' for t in val_data['native'].tolist()]\n",
    "    \n",
    "    # Build character-level tokenizers\n",
    "    input_tokenizer = Tokenizer(char_level=True, oov_token=None)\n",
    "    input_tokenizer.fit_on_texts(input_texts + val_input_texts)\n",
    "    \n",
    "    target_tokenizer = Tokenizer(char_level=True, oov_token=None)\n",
    "    target_tokenizer.fit_on_texts(target_texts + val_target_texts)\n",
    "    \n",
    "    # Find max lengths\n",
    "    max_in = max(len(txt) for txt in input_texts + val_input_texts)\n",
    "    max_out = max(len(txt) for txt in target_texts + val_target_texts)\n",
    "    \n",
    "    # Convert to sequences and pad\n",
    "    encoder_input_train = pad_sequences(\n",
    "        input_tokenizer.texts_to_sequences(input_texts),\n",
    "        maxlen=max_in,\n",
    "        padding='post'\n",
    "    )\n",
    "    decoder_input_train = pad_sequences(\n",
    "        target_tokenizer.texts_to_sequences(target_texts),\n",
    "        maxlen=max_out,\n",
    "        padding='post'\n",
    "    )\n",
    "    decoder_target_train = np.array(decoder_input_train)[:, 1:]\n",
    "    decoder_input_train = np.array(decoder_input_train)[:, :-1]\n",
    "    \n",
    "    # Same for validation set\n",
    "    encoder_input_val = pad_sequences(\n",
    "        input_tokenizer.texts_to_sequences(val_input_texts),\n",
    "        maxlen=max_in,\n",
    "        padding='post'\n",
    "    )\n",
    "    decoder_input_val = pad_sequences(\n",
    "        target_tokenizer.texts_to_sequences(val_target_texts),\n",
    "        maxlen=max_out,\n",
    "        padding='post'\n",
    "    )\n",
    "    decoder_target_val = np.array(decoder_input_val)[:, 1:]\n",
    "    decoder_input_val = np.array(decoder_input_val)[:, :-1]\n",
    "    \n",
    "    return {\n",
    "        'input_tokenizer': input_tokenizer,\n",
    "        'target_tokenizer': target_tokenizer,\n",
    "        'max_in': max_in,\n",
    "        'max_out': max_out,\n",
    "        'encoder_input_train': encoder_input_train,\n",
    "        'decoder_input_train': decoder_input_train,\n",
    "        'decoder_target_train': decoder_target_train,\n",
    "        'encoder_input_val': encoder_input_val,\n",
    "        'decoder_input_val': decoder_input_val,\n",
    "        'decoder_target_val': decoder_target_val,\n",
    "        'input_texts': input_texts,\n",
    "        'target_texts': target_texts,\n",
    "        'val_input_texts': val_input_texts,\n",
    "        'val_target_texts': val_target_texts\n",
    "    }\n",
    "\n",
    "# Seq2Seq model with configurable parameters\n",
    "class VanillaSeq2Seq:\n",
    "    def __init__(self,\n",
    "                 input_vocab_size,\n",
    "                 target_vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 cell_type='LSTM',\n",
    "                 dropout_rate=0.2,\n",
    "                 num_encoder_layers=1,\n",
    "                 num_decoder_layers=1):\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cell_type = cell_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _rnn_layer(self, return_sequences, return_state):\n",
    "        \"\"\"Factory for one RNN/LSTM/GRU layer.\"\"\"\n",
    "        if self.cell_type == 'LSTM':\n",
    "            return LSTM(self.hidden_dim,\n",
    "                        return_sequences=return_sequences,\n",
    "                        return_state=return_state)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            return GRU(self.hidden_dim,\n",
    "                       return_sequences=return_sequences,\n",
    "                       return_state=return_state)\n",
    "        else:  # 'RNN'\n",
    "            return SimpleRNN(self.hidden_dim,\n",
    "                             return_sequences=return_sequences,\n",
    "                             return_state=return_state)\n",
    "\n",
    "    \n",
    "    def _build_model(self):\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
    "        x = Embedding(self.input_vocab_size, self.embedding_dim)(encoder_inputs)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "        \n",
    "        # Stack encoder layers\n",
    "        encoder_states = []\n",
    "        for i in range(self.num_encoder_layers):\n",
    "            # last encoder layer returns only state, earlier ones return sequences\n",
    "            rs = (i < self.num_encoder_layers - 1)\n",
    "            if self.cell_type == 'LSTM':\n",
    "                x, state_h, state_c = LSTM(\n",
    "                    self.hidden_dim,\n",
    "                    return_sequences=rs,\n",
    "                    return_state=True,\n",
    "                    name=f'enc_lstm_{i}'\n",
    "                )(x)\n",
    "                encoder_states = [state_h, state_c]\n",
    "            else:\n",
    "                x, state_h = self._rnn_layer(\n",
    "                    return_sequences=rs,\n",
    "                    return_state=True\n",
    "                )(x)\n",
    "                encoder_states = [state_h]\n",
    "        \n",
    "        decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "        y = Embedding(self.target_vocab_size, self.embedding_dim)(decoder_inputs)\n",
    "        y = Dropout(self.dropout_rate)(y)\n",
    "        \n",
    "        # Stack decoder layers\n",
    "        for i in range(self.num_decoder_layers):\n",
    "            rs = True  # decoder always returns sequences\n",
    "            if self.cell_type == 'LSTM':\n",
    "                # feed initial_state only to the first decoder layer\n",
    "                init_st = encoder_states if i == 0 else None\n",
    "                y, dh, dc = LSTM(\n",
    "                    self.hidden_dim, \n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    name=f'dec_lstm_{i}'\n",
    "                )(y, initial_state=init_st) if init_st else LSTM(\n",
    "                    self.hidden_dim,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    name=f'dec_lstm_{i}'\n",
    "                )(y)\n",
    "            else:\n",
    "                init_st = encoder_states if i == 0 else None\n",
    "                y, dh = self._rnn_layer(\n",
    "                    return_sequences=True,\n",
    "                    return_state=True\n",
    "                )(y, initial_state=init_st) if init_st else self._rnn_layer(\n",
    "                    return_sequences=True,\n",
    "                    return_state=True\n",
    "                )(y)\n",
    "        \n",
    "        # Final projection\n",
    "        outputs = Dense(self.target_vocab_size, activation='softmax')(y)\n",
    "        return Model([encoder_inputs, decoder_inputs], outputs)\n",
    "    \n",
    "    def compile(self, optimizer='adam', loss='sparse_categorical_crossentropy'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, train_data, val_data, batch_size=64, epochs=8, callbacks=None):\n",
    "        return self.model.fit(\n",
    "            [train_data['encoder_input'], train_data['decoder_input']],\n",
    "            np.expand_dims(train_data['decoder_target'], -1),\n",
    "            validation_data=(\n",
    "                [val_data['encoder_input'], val_data['decoder_input']],\n",
    "                np.expand_dims(val_data['decoder_target'], -1)\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "def run_wandb_sweep(processed_data):\n",
    "    # Define sweep configuration\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': 'val_accuracy',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'embedding_dim': {\n",
    "                'values': [16, 32, 64, 128]\n",
    "            },\n",
    "            'hidden_dim': {\n",
    "                'values': [32, 64, 128, 256]\n",
    "            },\n",
    "            'cell_type': {\n",
    "                'values': ['RNN', 'GRU', 'LSTM']\n",
    "            },\n",
    "            'dropout_rate': {\n",
    "                'values': [0.1, 0.2, 0.3]\n",
    "            },\n",
    "            'num_encoder_layers': {\n",
    "                'values': [1, 2]\n",
    "            },\n",
    "            'num_decoder_layers': {\n",
    "                'values': [1, 2]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Initialize sweep\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"DA_seq2seq_transliteration\")\n",
    "    \n",
    "    # Define the training function\n",
    "    def train_model():\n",
    "        # Make sure we're in a clean wandb state\n",
    "        try:\n",
    "            wandb.finish()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Start a new wandb run\n",
    "        run = wandb.init()\n",
    "        \n",
    "        # Access hyperparameters from wandb\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Create model with hyperparameters from wandb\n",
    "        input_vocab_size = len(processed_data['input_tokenizer'].word_index) + 1\n",
    "        target_vocab_size = len(processed_data['target_tokenizer'].word_index) + 1\n",
    "        \n",
    "        model = VanillaSeq2Seq(\n",
    "            input_vocab_size=input_vocab_size,\n",
    "            target_vocab_size=target_vocab_size,\n",
    "            embedding_dim=config.embedding_dim,\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            cell_type=config.cell_type,\n",
    "            dropout_rate=config.dropout_rate,\n",
    "            num_encoder_layers=config.num_encoder_layers,\n",
    "            num_decoder_layers=config.num_decoder_layers\n",
    "        )\n",
    "        \n",
    "        model.compile()\n",
    "        \n",
    "        # Configure wandb callback\n",
    "        wandb_callback = WandbCallback(\n",
    "            log_model=False,\n",
    "            save_graph=False,\n",
    "            save_model=False\n",
    "        )\n",
    "        \n",
    "        # Compute model complexity metrics\n",
    "        D = config.embedding_dim\n",
    "        H = config.hidden_dim\n",
    "        L_e = config.num_encoder_layers\n",
    "        L_d = config.num_decoder_layers\n",
    "        T_enc = processed_data['encoder_input_train'].shape[1]\n",
    "        T_dec = processed_data['decoder_input_train'].shape[1]\n",
    "        \n",
    "        flops_per_step = 4 * (H * D + H * H)\n",
    "        total_enc_flops = L_e * T_enc * flops_per_step\n",
    "        total_dec_flops = L_d * T_dec * flops_per_step\n",
    "        total_flops = total_enc_flops + total_dec_flops\n",
    "        \n",
    "        total_params = model.model.count_params()\n",
    "        \n",
    "        print(f\"Embedding dim: {D}, Hidden dim: {H}\")\n",
    "        print(f\"Encoder layers: {L_e}, Decoder layers: {L_d}\")\n",
    "        print(f\"Cell type: {config.cell_type}, Dropout: {config.dropout_rate}\")\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Total FLOPs: {total_flops:,}\")\n",
    "        \n",
    "        # Log model complexity metrics\n",
    "        wandb.log({\n",
    "            \"total_flops\": total_flops,\n",
    "            \"total_params\": total_params\n",
    "        })\n",
    "        \n",
    "        # Train the model\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_data={\n",
    "                'encoder_input': processed_data['encoder_input_train'],\n",
    "                'decoder_input': processed_data['decoder_input_train'],\n",
    "                'decoder_target': processed_data['decoder_target_train']\n",
    "            },\n",
    "            val_data={\n",
    "                'encoder_input': processed_data['encoder_input_val'],\n",
    "                'decoder_input': processed_data['decoder_input_val'],\n",
    "                'decoder_target': processed_data['decoder_target_val']\n",
    "            },\n",
    "            batch_size=64,\n",
    "            epochs=8,\n",
    "            callbacks=[wandb_callback]\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Log additional metrics\n",
    "        wandb.log({\n",
    "            \"training_time\": training_time,\n",
    "            \"final_train_accuracy\": history.history['accuracy'][-1],\n",
    "            \"final_val_accuracy\": history.history['val_accuracy'][-1]\n",
    "        })\n",
    "        \n",
    "        # Clean up (important to avoid memory leaks)\n",
    "        tf.keras.backend.clear_session()\n",
    "        run.finish()\n",
    "    \n",
    "    # Run the sweep\n",
    "    wandb.agent(sweep_id, train_model, count=7)  # Adjust count based on time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T08:02:06.116777Z",
     "iopub.status.busy": "2025-05-20T08:02:06.116449Z",
     "iopub.status.idle": "2025-05-20T10:01:42.693865Z",
     "shell.execute_reply": "2025-05-20T10:01:42.693033Z",
     "shell.execute_reply.started": "2025-05-20T08:02:06.116755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully! Train size: 44202\n",
      "Data processed successfully!\n",
      "Starting hyperparameter sweep...\n",
      "Create sweep with ID: mpq5soqm\n",
      "Sweep URL: https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: inksfj02 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_080214-inksfj02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/inksfj02' target=\"_blank\">charmed-sweep-1</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/inksfj02' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/inksfj02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 64, Hidden dim: 256\n",
      "Encoder layers: 2, Decoder layers: 1\n",
      "Cell type: LSTM, Dropout: 0.3\n",
      "Total parameters: 1,196,125\n",
      "Total FLOPs: 19,333,120\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 196ms/step - accuracy: 0.7037 - loss: 1.1084 - val_accuracy: 0.7615 - val_loss: 0.7974\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 194ms/step - accuracy: 0.7614 - loss: 0.7937 - val_accuracy: 0.8196 - val_loss: 0.5974\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 196ms/step - accuracy: 0.8165 - loss: 0.5964 - val_accuracy: 0.8607 - val_loss: 0.4616\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 198ms/step - accuracy: 0.8617 - loss: 0.4554 - val_accuracy: 0.9029 - val_loss: 0.3273\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 196ms/step - accuracy: 0.8995 - loss: 0.3332 - val_accuracy: 0.9259 - val_loss: 0.2486\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 191ms/step - accuracy: 0.9226 - loss: 0.2538 - val_accuracy: 0.9383 - val_loss: 0.2057\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 193ms/step - accuracy: 0.9357 - loss: 0.2088 - val_accuracy: 0.9444 - val_loss: 0.1811\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 193ms/step - accuracy: 0.9436 - loss: 0.1793 - val_accuracy: 0.9482 - val_loss: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▄▆▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▅▃▂▂▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9442</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.17003</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.9442</td></tr><tr><td>final_val_accuracy</td><td>0.9482</td></tr><tr><td>loss</td><td>0.17732</td></tr><tr><td>total_flops</td><td>19333120</td></tr><tr><td>total_params</td><td>1196125</td></tr><tr><td>training_time</td><td>1083.24335</td></tr><tr><td>val_accuracy</td><td>0.9482</td></tr><tr><td>val_loss</td><td>0.17003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-1</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/inksfj02' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/inksfj02</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_080214-inksfj02/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0r31b8ft with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_082035-0r31b8ft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0r31b8ft' target=\"_blank\">robust-sweep-2</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0r31b8ft' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0r31b8ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 16, Hidden dim: 32\n",
      "Encoder layers: 1, Decoder layers: 2\n",
      "Cell type: GRU, Dropout: 0.2\n",
      "Total parameters: 18,381\n",
      "Total FLOPs: 374,784\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.6691 - loss: 1.3930 - val_accuracy: 0.7426 - val_loss: 0.8798\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.7361 - loss: 0.9034 - val_accuracy: 0.7523 - val_loss: 0.8497\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.7413 - loss: 0.8765 - val_accuracy: 0.7572 - val_loss: 0.8311\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.7448 - loss: 0.8618 - val_accuracy: 0.7588 - val_loss: 0.8153\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.7476 - loss: 0.8472 - val_accuracy: 0.7629 - val_loss: 0.7999\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.7528 - loss: 0.8329 - val_accuracy: 0.7690 - val_loss: 0.7848\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.7580 - loss: 0.8145 - val_accuracy: 0.7751 - val_loss: 0.7537\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.7647 - loss: 0.7848 - val_accuracy: 0.7821 - val_loss: 0.7285\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▅▆▆▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▃▃▃▂▂▂▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▅▆▇█</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76626</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.72848</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.76626</td></tr><tr><td>final_val_accuracy</td><td>0.78208</td></tr><tr><td>loss</td><td>0.77915</td></tr><tr><td>total_flops</td><td>374784</td></tr><tr><td>total_params</td><td>18381</td></tr><tr><td>training_time</td><td>180.86946</td></tr><tr><td>val_accuracy</td><td>0.78208</td></tr><tr><td>val_loss</td><td>0.72848</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-sweep-2</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0r31b8ft' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0r31b8ft</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_082035-0r31b8ft/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hwigli45 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_082353-hwigli45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/hwigli45' target=\"_blank\">honest-sweep-3</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/hwigli45' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/hwigli45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 16, Hidden dim: 256\n",
      "Encoder layers: 1, Decoder layers: 1\n",
      "Cell type: LSTM, Dropout: 0.2\n",
      "Total parameters: 568,045\n",
      "Total FLOPs: 11,141,120\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 112ms/step - accuracy: 0.6936 - loss: 1.1958 - val_accuracy: 0.7601 - val_loss: 0.8091\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 112ms/step - accuracy: 0.7529 - loss: 0.8280 - val_accuracy: 0.7808 - val_loss: 0.7201\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 114ms/step - accuracy: 0.7740 - loss: 0.7476 - val_accuracy: 0.8014 - val_loss: 0.6486\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 115ms/step - accuracy: 0.7905 - loss: 0.6829 - val_accuracy: 0.8204 - val_loss: 0.5936\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 137ms/step - accuracy: 0.8057 - loss: 0.6309 - val_accuracy: 0.8310 - val_loss: 0.5477\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 119ms/step - accuracy: 0.8207 - loss: 0.5749 - val_accuracy: 0.8410 - val_loss: 0.5050\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 117ms/step - accuracy: 0.8364 - loss: 0.5211 - val_accuracy: 0.8607 - val_loss: 0.4440\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 118ms/step - accuracy: 0.8518 - loss: 0.4686 - val_accuracy: 0.8792 - val_loss: 0.3891\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▆▆▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▅▄▃▂▂▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▅▅▆▇█</td></tr><tr><td>val_loss</td><td>█▇▅▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85587</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.38906</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.85587</td></tr><tr><td>final_val_accuracy</td><td>0.87918</td></tr><tr><td>loss</td><td>0.4566</td></tr><tr><td>total_flops</td><td>11141120</td></tr><tr><td>total_params</td><td>568045</td></tr><tr><td>training_time</td><td>658.08906</td></tr><tr><td>val_accuracy</td><td>0.87918</td></tr><tr><td>val_loss</td><td>0.38906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-3</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/hwigli45' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/hwigli45</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_082353-hwigli45/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sydm6xg4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_083507-sydm6xg4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/sydm6xg4' target=\"_blank\">swept-sweep-4</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/sydm6xg4' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/sydm6xg4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 64, Hidden dim: 256\n",
      "Encoder layers: 2, Decoder layers: 2\n",
      "Cell type: LSTM, Dropout: 0.3\n",
      "Total parameters: 1,721,437\n",
      "Total FLOPs: 26,214,400\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 284ms/step - accuracy: 0.6965 - loss: 1.1433 - val_accuracy: 0.7635 - val_loss: 0.7950\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 275ms/step - accuracy: 0.7635 - loss: 0.7890 - val_accuracy: 0.8123 - val_loss: 0.6225\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 279ms/step - accuracy: 0.8136 - loss: 0.6096 - val_accuracy: 0.8693 - val_loss: 0.4282\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 276ms/step - accuracy: 0.8685 - loss: 0.4264 - val_accuracy: 0.9098 - val_loss: 0.2975\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 273ms/step - accuracy: 0.9052 - loss: 0.3063 - val_accuracy: 0.9304 - val_loss: 0.2281\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 272ms/step - accuracy: 0.9284 - loss: 0.2319 - val_accuracy: 0.9400 - val_loss: 0.1944\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 276ms/step - accuracy: 0.9406 - loss: 0.1899 - val_accuracy: 0.9468 - val_loss: 0.1733\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 281ms/step - accuracy: 0.9479 - loss: 0.1621 - val_accuracy: 0.9465 - val_loss: 0.1685\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▆▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇▇███</td></tr><tr><td>val_loss</td><td>█▆▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94798</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.16852</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.94798</td></tr><tr><td>final_val_accuracy</td><td>0.94652</td></tr><tr><td>loss</td><td>0.16199</td></tr><tr><td>total_flops</td><td>26214400</td></tr><tr><td>total_params</td><td>1721437</td></tr><tr><td>training_time</td><td>1541.36688</td></tr><tr><td>val_accuracy</td><td>0.94652</td></tr><tr><td>val_loss</td><td>0.16852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-4</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/sydm6xg4' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/sydm6xg4</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_083507-sydm6xg4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1da0cgf0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_090104-1da0cgf0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/1da0cgf0' target=\"_blank\">hearty-sweep-5</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/1da0cgf0' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/1da0cgf0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, Hidden dim: 256\n",
      "Encoder layers: 2, Decoder layers: 2\n",
      "Cell type: LSTM, Dropout: 0.3\n",
      "Total parameters: 1,858,461\n",
      "Total FLOPs: 31,457,280\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 290ms/step - accuracy: 0.6999 - loss: 1.1278 - val_accuracy: 0.7640 - val_loss: 0.7907\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 282ms/step - accuracy: 0.7704 - loss: 0.7635 - val_accuracy: 0.8331 - val_loss: 0.5421\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 283ms/step - accuracy: 0.8366 - loss: 0.5290 - val_accuracy: 0.8907 - val_loss: 0.3595\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 283ms/step - accuracy: 0.8925 - loss: 0.3483 - val_accuracy: 0.9280 - val_loss: 0.2395\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 289ms/step - accuracy: 0.9258 - loss: 0.2404 - val_accuracy: 0.9406 - val_loss: 0.1942\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 288ms/step - accuracy: 0.9410 - loss: 0.1892 - val_accuracy: 0.9475 - val_loss: 0.1709\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 286ms/step - accuracy: 0.9492 - loss: 0.1588 - val_accuracy: 0.9488 - val_loss: 0.1626\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 287ms/step - accuracy: 0.9544 - loss: 0.1399 - val_accuracy: 0.9517 - val_loss: 0.1528\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▆▇███</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▄▃▂▁▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95375</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.15277</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.95375</td></tr><tr><td>final_val_accuracy</td><td>0.9517</td></tr><tr><td>loss</td><td>0.14132</td></tr><tr><td>total_flops</td><td>31457280</td></tr><tr><td>total_params</td><td>1858461</td></tr><tr><td>training_time</td><td>1597.12138</td></tr><tr><td>val_accuracy</td><td>0.9517</td></tr><tr><td>val_loss</td><td>0.15277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-5</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/1da0cgf0' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/1da0cgf0</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_090104-1da0cgf0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vihxk2yq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_092756-vihxk2yq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/vihxk2yq' target=\"_blank\">misunderstood-sweep-6</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/vihxk2yq' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/vihxk2yq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, Hidden dim: 256\n",
      "Encoder layers: 2, Decoder layers: 1\n",
      "Cell type: GRU, Dropout: 0.1\n",
      "Total parameters: 1,007,005\n",
      "Total FLOPs: 23,199,744\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 179ms/step - accuracy: 0.7157 - loss: 1.0475 - val_accuracy: 0.7969 - val_loss: 0.6725\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 179ms/step - accuracy: 0.8153 - loss: 0.6139 - val_accuracy: 0.8872 - val_loss: 0.3759\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 178ms/step - accuracy: 0.8920 - loss: 0.3576 - val_accuracy: 0.9281 - val_loss: 0.2485\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 175ms/step - accuracy: 0.9271 - loss: 0.2398 - val_accuracy: 0.9403 - val_loss: 0.1994\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 176ms/step - accuracy: 0.9407 - loss: 0.1928 - val_accuracy: 0.9415 - val_loss: 0.1880\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 178ms/step - accuracy: 0.9468 - loss: 0.1675 - val_accuracy: 0.9477 - val_loss: 0.1733\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 179ms/step - accuracy: 0.9514 - loss: 0.1513 - val_accuracy: 0.9497 - val_loss: 0.1632\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 183ms/step - accuracy: 0.9546 - loss: 0.1380 - val_accuracy: 0.9499 - val_loss: 0.1622\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇████</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▅▃▂▁▁▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇█████</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95386</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.16218</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.95386</td></tr><tr><td>final_val_accuracy</td><td>0.94991</td></tr><tr><td>loss</td><td>0.14016</td></tr><tr><td>total_flops</td><td>23199744</td></tr><tr><td>total_params</td><td>1007005</td></tr><tr><td>training_time</td><td>996.6674</td></tr><tr><td>val_accuracy</td><td>0.94991</td></tr><tr><td>val_loss</td><td>0.16218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-6</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/vihxk2yq' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/vihxk2yq</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_092756-vihxk2yq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6n1ssi28 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_094450-6n1ssi28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/6n1ssi28' target=\"_blank\">cerulean-sweep-7</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mpq5soqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/6n1ssi28' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/6n1ssi28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, Hidden dim: 256\n",
      "Encoder layers: 2, Decoder layers: 1\n",
      "Cell type: GRU, Dropout: 0.3\n",
      "Total parameters: 1,007,005\n",
      "Total FLOPs: 23,199,744\n",
      "Epoch 1/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 190ms/step - accuracy: 0.7152 - loss: 1.0636 - val_accuracy: 0.7932 - val_loss: 0.6926\n",
      "Epoch 2/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 183ms/step - accuracy: 0.8013 - loss: 0.6613 - val_accuracy: 0.8663 - val_loss: 0.4354\n",
      "Epoch 3/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 184ms/step - accuracy: 0.8725 - loss: 0.4221 - val_accuracy: 0.9152 - val_loss: 0.2891\n",
      "Epoch 4/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 181ms/step - accuracy: 0.9130 - loss: 0.2876 - val_accuracy: 0.9335 - val_loss: 0.2224\n",
      "Epoch 5/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 176ms/step - accuracy: 0.9320 - loss: 0.2232 - val_accuracy: 0.9418 - val_loss: 0.1931\n",
      "Epoch 6/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 175ms/step - accuracy: 0.9407 - loss: 0.1891 - val_accuracy: 0.9459 - val_loss: 0.1762\n",
      "Epoch 7/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 175ms/step - accuracy: 0.9465 - loss: 0.1690 - val_accuracy: 0.9490 - val_loss: 0.1664\n",
      "Epoch 8/8\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 175ms/step - accuracy: 0.9502 - loss: 0.1550 - val_accuracy: 0.9498 - val_loss: 0.1614\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▅▃▂▂▁▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_params</td><td>▁</td></tr><tr><td>training_time</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94977</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.16139</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>final_train_accuracy</td><td>0.94977</td></tr><tr><td>final_val_accuracy</td><td>0.9498</td></tr><tr><td>loss</td><td>0.15592</td></tr><tr><td>total_flops</td><td>23199744</td></tr><tr><td>total_params</td><td>1007005</td></tr><tr><td>training_time</td><td>1005.06698</td></tr><tr><td>val_accuracy</td><td>0.9498</td></tr><tr><td>val_loss</td><td>0.16139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-7</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/6n1ssi28' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/6n1ssi28</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_094450-6n1ssi28/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure TensorFlow doesn't reserve all GPU memory\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        train_data, val_data, test_data = load_dakshina_data(lang='hi')\n",
    "        print(f\"Data loaded successfully! Train size: {len(train_data)}\")\n",
    "        \n",
    "        # Process data\n",
    "        processed_data = process_data(train_data, val_data)\n",
    "        print(\"Data processed successfully!\")\n",
    "        \n",
    "        # Run sweep\n",
    "        print(\"Starting hyperparameter sweep...\")\n",
    "        run_wandb_sweep(processed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T15:06:48.526657Z",
     "iopub.status.busy": "2025-05-20T15:06:48.526122Z",
     "iopub.status.idle": "2025-05-20T15:08:17.788260Z",
     "shell.execute_reply": "2025-05-20T15:08:17.787702Z",
     "shell.execute_reply.started": "2025-05-20T15:06:48.526635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data processed and tokenizers created.\n",
      "✅ Step A complete\n",
      "🔍 Fetching wandb runs...\n",
      "✅ Best run: s35s9ajw with val_accuracy=0.9523\n",
      "Best sweep config: {'cell_type': 'LSTM', 'hidden_dim': 256, 'dropout_rate': 0.1, 'embedding_dim': 128, 'num_decoder_layers': 1, 'num_encoder_layers': 2}\n",
      "✅ Step B complete\n",
      "🔧 Rebuilding model...\n",
      "✅ Model built and compiled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_150650-q8n80qdx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/q8n80qdx' target=\"_blank\">q4_retrain_best_model</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/q8n80qdx' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/q8n80qdx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Step D complete. Beginning training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.7129 - loss: 1.0550 - val_accuracy: 0.7994 - val_loss: 0.6679\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8086 - loss: 0.6327 - val_accuracy: 0.8680 - val_loss: 0.4357\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.8765 - loss: 0.4036 - val_accuracy: 0.9099 - val_loss: 0.2952\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.2655 - val_accuracy: 0.9378 - val_loss: 0.2096\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.2000 - val_accuracy: 0.9453 - val_loss: 0.1796\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9477 - loss: 0.1666 - val_accuracy: 0.9488 - val_loss: 0.1638\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9526 - loss: 0.1477 - val_accuracy: 0.9519 - val_loss: 0.1548\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1333 - val_accuracy: 0.9511 - val_loss: 0.1523\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.1212 - val_accuracy: 0.9539 - val_loss: 0.1450\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.1142 - val_accuracy: 0.9540 - val_loss: 0.1425\n",
      "✅ Training complete\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇▇█████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95989</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.14247</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.11669</td></tr><tr><td>val_accuracy</td><td>0.95404</td></tr><tr><td>val_loss</td><td>0.14247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">q4_retrain_best_model</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/q8n80qdx' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/q8n80qdx</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_150650-q8n80qdx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wandb finished\n",
      "✅ Weights loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import callbacks as keras_cb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "# ─── A) Bring data & tokenizers back into scope ───────────────────\n",
    "try:\n",
    "    pi = processed_data\n",
    "    input_tokenizer  = pi['input_tokenizer']\n",
    "    target_tokenizer = pi['target_tokenizer']\n",
    "    max_in, max_out = pi['max_in'], pi['max_out']\n",
    "    encoder_input_train = pi['encoder_input_train']\n",
    "    decoder_input_train = pi['decoder_input_train']\n",
    "    decoder_target_train= pi['decoder_target_train']\n",
    "    encoder_input_val   = pi['encoder_input_val']\n",
    "    decoder_input_val   = pi['decoder_input_val']\n",
    "    decoder_target_val  = pi['decoder_target_val']\n",
    "    print(\"✅ Data and tokenizers loaded from cache.\")\n",
    "except NameError:\n",
    "    train_data, val_data, test_data = load_dakshina_data(lang='hi')\n",
    "    pi = process_data(train_data, val_data)\n",
    "    input_tokenizer  = pi['input_tokenizer']\n",
    "    target_tokenizer = pi['target_tokenizer']\n",
    "    max_in, max_out = pi['max_in'], pi['max_out']\n",
    "    encoder_input_train = pi['encoder_input_train']\n",
    "    decoder_input_train = pi['decoder_input_train']\n",
    "    decoder_target_train= pi['decoder_target_train']\n",
    "    encoder_input_val   = pi['encoder_input_val']\n",
    "    decoder_input_val   = pi['decoder_input_val']\n",
    "    decoder_target_val  = pi['decoder_target_val']\n",
    "    print(\"✅ Data processed and tokenizers created.\")\n",
    "print(\"✅ Step A complete\")\n",
    "\n",
    "# ─── B) Fetch best hyperparams ─────────────────────────────\n",
    "api    = wandb.Api()\n",
    "ENTITY = \"mm21b044-indian-institute-of-technology-madras\"\n",
    "PROJ   = \"DA_seq2seq_transliteration\"\n",
    "\n",
    "print(\"🔍 Fetching wandb runs...\")\n",
    "all_runs   = api.runs(f\"{ENTITY}/{PROJ}\")\n",
    "valid_runs = [r for r in all_runs if 'final_val_accuracy' in r.summary]\n",
    "best_run   = max(valid_runs, key=lambda r: r.summary['final_val_accuracy'])\n",
    "best_cfg   = best_run.config\n",
    "\n",
    "print(f\"✅ Best run: {best_run.id} with val_accuracy={best_run.summary['final_val_accuracy']:.4f}\")\n",
    "print(\"Best sweep config:\", best_cfg)\n",
    "\n",
    "inp_vocab = len(input_tokenizer.word_index) + 1\n",
    "tgt_vocab = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "BEST_HP = {\n",
    "    'input_vocab_size':   inp_vocab,\n",
    "    'target_vocab_size':  tgt_vocab,\n",
    "    'embedding_dim':      best_cfg['embedding_dim'],\n",
    "    'hidden_dim':         best_cfg['hidden_dim'],\n",
    "    'cell_type':          best_cfg['cell_type'],\n",
    "    'dropout_rate':       best_cfg['dropout_rate'],\n",
    "    'num_encoder_layers': best_cfg.get('num_encoder_layers', 1),\n",
    "    'num_decoder_layers': best_cfg.get('num_decoder_layers', 1)\n",
    "}\n",
    "print(\"✅ Step B complete\")\n",
    "\n",
    "# ─── C) Rebuild model ─────────────────────────────────────────────\n",
    "print(\"🔧 Rebuilding model...\")\n",
    "model = VanillaSeq2Seq(**BEST_HP)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "print(\"✅ Model built and compiled.\")\n",
    "\n",
    "# ─── D) Prepare for retraining ───────────────────────────────────\n",
    "y_train = np.expand_dims(decoder_target_train, -1)\n",
    "y_val   = np.expand_dims(decoder_target_val, -1)\n",
    "\n",
    "wandb.init(project=PROJ, name=\"q4_retrain_best_model\", reinit=True)\n",
    "wandb.config.update(BEST_HP, allow_val_change=True)\n",
    "\n",
    "checkpoint_path = \"/kaggle/working/q4_best_model.weights.h5\"\n",
    "cb = [\n",
    "    keras_cb.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss'\n",
    "    ),\n",
    "    WandbCallback(\n",
    "        save_model=False,\n",
    "        log_weights=True,\n",
    "        save_graph=False\n",
    "    )\n",
    "]\n",
    "print(\"✅ Step D complete. Beginning training...\")\n",
    "\n",
    "# ─── E) Retrain ───────────────────────────────────────────────────\n",
    "history = model.model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    y_train,\n",
    "    batch_size=wandb.config.get('batch_size', 64),\n",
    "    epochs=10,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], y_val),\n",
    "    callbacks=cb,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"✅ Training complete\")\n",
    "\n",
    "wandb.finish()\n",
    "print(\"✅ wandb finished\")\n",
    "\n",
    "# ─── F) Load weights and prepare test ─────────────────────────────\n",
    "model.model.load_weights(checkpoint_path)\n",
    "print(\"✅ Weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T14:14:16.986631Z",
     "iopub.status.busy": "2025-05-20T14:14:16.986176Z",
     "iopub.status.idle": "2025-05-20T15:00:21.996152Z",
     "shell.execute_reply": "2025-05-20T15:00:21.995517Z",
     "shell.execute_reply.started": "2025-05-20T14:14:16.986611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Starting decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding examples: 100%|██████████| 4502/4502 [45:57<00:00,  1.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Decoding done\n",
      "✅ Final test exact-match accuracy: 3.5318%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_150014-b1ic3mri</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/b1ic3mri' target=\"_blank\">q4_test_eval</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/b1ic3mri' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/b1ic3mri</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.03532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">q4_test_eval</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/b1ic3mri' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/b1ic3mri</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_150014-b1ic3mri/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test accuracy logged to wandb\n",
      "✅ Saved predictions to /kaggle/working/predictions_vanilla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3273880890.py:38: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plot displayed\n"
     ]
    }
   ],
   "source": [
    "test_texts = test_data['latin'].astype(str).tolist()\n",
    "true_texts = test_data['native'].astype(str).tolist()\n",
    "\n",
    "enc_test = pad_sequences(\n",
    "    input_tokenizer.texts_to_sequences(test_texts),\n",
    "    maxlen=max_in, padding='post'\n",
    ")\n",
    "start_idx = target_tokenizer.texts_to_sequences(['\\t'])[0][0]\n",
    "index_to_char = {i: ch for ch, i in target_tokenizer.word_index.items()}\n",
    "index_to_char[0] = ''\n",
    "\n",
    "def decode(seq):\n",
    "    seq = seq[np.newaxis]\n",
    "    dec_input = np.array([[start_idx]])\n",
    "    out = ''\n",
    "    for _ in range(max_out):\n",
    "        preds = model.model.predict([seq, dec_input], verbose=0)\n",
    "        nxt = np.argmax(preds[0, -1, :])\n",
    "        if nxt==0 or index_to_char[nxt]=='\\n': break\n",
    "        out += index_to_char[nxt]\n",
    "        dec_input = np.concatenate([dec_input, [[nxt]]], axis=1)\n",
    "    return out\n",
    "print(\"🧠 Starting decoding...\")\n",
    "preds, corr = [], 0\n",
    "\n",
    "for i, s in enumerate(tqdm(enc_test, desc=\"Decoding examples\")):\n",
    "    p = decode(s)\n",
    "    preds.append(p)\n",
    "    if p == true_texts[i]:\n",
    "        corr += 1\n",
    "\n",
    "print(\"✅ Decoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T15:10:56.196172Z",
     "iopub.status.busy": "2025-05-20T15:10:56.195504Z",
     "iopub.status.idle": "2025-05-20T15:11:03.498260Z",
     "shell.execute_reply": "2025-05-20T15:11:03.497278Z",
     "shell.execute_reply.started": "2025-05-20T15:10:56.196148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final test exact-match accuracy: 3.5318%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_151056-33ptrpg2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/33ptrpg2' target=\"_blank\">q4_test_eval</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/33ptrpg2' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/33ptrpg2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.03532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">q4_test_eval</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/33ptrpg2' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/33ptrpg2</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_151056-33ptrpg2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test accuracy logged to wandb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Latin</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>अंक</td>\n",
       "      <td>ank</td>\n",
       "      <td>amat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंक</td>\n",
       "      <td>anka</td>\n",
       "      <td>amat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकित</td>\n",
       "      <td>ankit</td>\n",
       "      <td>antati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकों</td>\n",
       "      <td>anakon</td>\n",
       "      <td>anaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकों</td>\n",
       "      <td>ankhon</td>\n",
       "      <td>anaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकों</td>\n",
       "      <td>ankon</td>\n",
       "      <td>anaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकोर</td>\n",
       "      <td>angkor</td>\n",
       "      <td>anrur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंकोर</td>\n",
       "      <td>ankor</td>\n",
       "      <td>anrur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>अंगारक</td>\n",
       "      <td>angaarak</td>\n",
       "      <td>angraar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_35/3018021838.py:30: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plot displayed\n"
     ]
    }
   ],
   "source": [
    "test_acc = corr / len(enc_test)\n",
    "print(f\"✅ Final test exact-match accuracy: {test_acc:.4%}\")\n",
    "\n",
    "# ─── G) Log test result ───────────────────────────────────────────\n",
    "wandb.init(project=PROJ, name=\"q4_test_eval\", reinit=True)\n",
    "wandb.log({\"test_accuracy\": test_acc})\n",
    "wandb.finish()\n",
    "print(\"✅ Test accuracy logged to wandb\")\n",
    "\n",
    "# ─── H) Save & display predictions ───────────────────────────────\n",
    "out_dir = \"/kaggle/working/predictions_vanilla\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Latin\":      test_texts[:9],\n",
    "    \"Reference\":  true_texts[:9],\n",
    "    \"Prediction\": preds[:9]\n",
    "})\n",
    "\n",
    "# Show as HTML table\n",
    "display(HTML(df.to_html(index=False)))\n",
    "\n",
    "fig, axes = plt.subplots(3,3,figsize=(9,9))\n",
    "for ax, idx in zip(axes.flatten(), range(9)):\n",
    "    txt = f\"In:  {test_texts[idx]}\\nRef: {true_texts[idx]}\\nPred:{preds[idx]}\"\n",
    "    ax.text(0,0.1, txt, wrap=True)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"✅ Plot displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T16:12:47.756918Z",
     "iopub.status.busy": "2025-05-20T16:12:47.756636Z",
     "iopub.status.idle": "2025-05-20T16:13:29.637172Z",
     "shell.execute_reply": "2025-05-20T16:13:29.636475Z",
     "shell.execute_reply.started": "2025-05-20T16:12:47.756898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mujwkszl\n",
      "Sweep URL: https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/mujwkszl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7sbn2n4l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_units: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025834492586700267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DA_seq2seq_transliteration' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-26 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_35/1007634987.py\", line 3, in train_attention_model\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1544, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1530, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 799, in init\n",
      "    wandb.run.finish()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 4238, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: noiqnlx6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_units: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00040058789111120814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DA_seq2seq_transliteration' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-27 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_35/1007634987.py\", line 3, in train_attention_model\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1544, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1530, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 799, in init\n",
      "    wandb.run.finish()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 4238, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6ighu4or with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_units: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0023441831450793284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DA_seq2seq_transliteration' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-28 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_35/1007634987.py\", line 3, in train_attention_model\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1544, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1530, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 799, in init\n",
      "    wandb.run.finish()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 4238, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for WandB Sweep (similar to Q2, but for attention model) ---\n",
    "def train_attention_model(config=None):\n",
    "    with wandb.init(config=config, project=\"DA_seq2seq_transliteration\", reinit=True):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Define model parameters from config\n",
    "        embedding_dim = config.embedding_dim\n",
    "        hidden_units = config.hidden_units\n",
    "        cell_type = config.cell_type\n",
    "        dropout_rate = config.dropout_rate\n",
    "        learning_rate = config.learning_rate\n",
    "\n",
    "        # Choose the RNN cell based on config\n",
    "        if cell_type == 'LSTM':\n",
    "            rnn_cell = LSTM\n",
    "        elif cell_type == 'GRU':\n",
    "            rnn_cell = GRU\n",
    "        else:\n",
    "            rnn_cell = SimpleRNN\n",
    "\n",
    "        # --- Encoder ---\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
    "        encoder_embedding = Embedding(num_encoder_tokens, embedding_dim)(encoder_inputs)\n",
    "        encoder_rnn = rnn_cell(hidden_units, return_sequences=True, return_state=True, dropout=dropout_rate, name='encoder_rnn')\n",
    "        encoder_outputs, state_h, state_c = encoder_rnn(encoder_embedding) # state_c will be None for GRU/SimpleRNN\n",
    "\n",
    "        encoder_states = [state_h, state_c] if cell_type == 'LSTM' else [state_h]\n",
    "\n",
    "        # --- Decoder ---\n",
    "        decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "        decoder_embedding = Embedding(num_decoder_tokens, embedding_dim)(decoder_inputs)\n",
    "        decoder_rnn = rnn_cell(hidden_units, return_sequences=True, return_state=True, dropout=dropout_rate, name='decoder_rnn')\n",
    "\n",
    "        # Implement Bahdanau Attention (Additive Attention)\n",
    "        # This is a common form of attention. Keras doesn't have a built-in Bahdanau layer, so we implement it.\n",
    "        # Alternatively, you can use a pre-built attention layer if available in a higher-level library like tf.keras.layers.Attention\n",
    "\n",
    "        # For simplicity, let's use a common approach:\n",
    "        # Dot product attention or scaled dot product attention is also popular\n",
    "        # This implementation uses a simple attention mechanism for demonstration.\n",
    "        # A more robust attention mechanism would typically involve a separate Attention layer\n",
    "        # For a basic additive attention:\n",
    "        # score = V * tanh(W1 * encoder_outputs + W2 * decoder_hidden_state)\n",
    "        # attention_weights = softmax(score)\n",
    "        # context_vector = attention_weights * encoder_outputs\n",
    "\n",
    "        # Keras official examples often use `tf.keras.layers.Attention` for simplicity, which implements scaled dot-product attention\n",
    "        attention_layer = tf.keras.layers.Attention()\n",
    "        \n",
    "        # We need the decoder to process one step at a time during inference,\n",
    "        # but for training, we can pass the whole sequence.\n",
    "        # The decoder initial state will be the encoder's last state.\n",
    "        \n",
    "        # The `decoder_outputs` will be used with `encoder_outputs` for attention.\n",
    "        # During training, the decoder's initial states come from the encoder's last states.\n",
    "        decoder_outputs_train, decoder_state_h_train, decoder_state_c_train = decoder_rnn(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "        # Apply Attention. The query is the decoder_outputs_train, and the value/key are encoder_outputs.\n",
    "        # The result of attention is the context vector.\n",
    "        attention_output = attention_layer([decoder_outputs_train, encoder_outputs])\n",
    "\n",
    "        # Concatenate attention output and decoder outputs\n",
    "        decoder_concat_input = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs_train, attention_output])\n",
    "\n",
    "        # Output layer\n",
    "        decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation='softmax', name='decoder_output'))\n",
    "        decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "        # Define the model\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        # Callbacks\n",
    "        callbacks = [WandbCallback()]\n",
    "\n",
    "        # Train the model (assuming you have train/validation data prepared)\n",
    "        # You'll need to adjust batch_size, epochs based on your data and computational resources\n",
    "        model.fit(\n",
    "            [encoder_input_data, decoder_input_data],\n",
    "            decoder_target_data,\n",
    "            batch_size=config.batch_size,\n",
    "            epochs=config.epochs,\n",
    "            validation_split=0.2, # Or use your explicit validation set\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # --- Save the best model ---\n",
    "        # WandB automatically saves the best model if you configure WandbCallback appropriately\n",
    "        # You can also manually save the model:\n",
    "        model.save(f\"best_attention_model_{wandb.run.name}.h5\")\n",
    "\n",
    "        # --- Inference setup (for prediction later) ---\n",
    "        # Encoder model for inference\n",
    "        encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
    "\n",
    "        # Decoder model for inference (needs to take encoder outputs and previous decoder state)\n",
    "        decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "        decoder_state_input_c = Input(shape=(hidden_units,)) if cell_type == 'LSTM' else None\n",
    "        \n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] if cell_type == 'LSTM' else [decoder_state_input_h]\n",
    "        \n",
    "        decoder_outputs_inference, state_h_inference, state_c_inference = decoder_rnn(\n",
    "            decoder_embedding, initial_state=decoder_states_inputs\n",
    "        )\n",
    "        decoder_states_inference = [state_h_inference, state_c_inference] if cell_type == 'LSTM' else [state_h_inference]\n",
    "\n",
    "        # Attention for inference\n",
    "        # The `encoder_outputs` from the encoder_model will be used here.\n",
    "        encoder_outputs_inference = Input(shape=(None, hidden_units,)) # Shape of encoder_outputs\n",
    "\n",
    "        attention_output_inference = attention_layer([decoder_outputs_inference, encoder_outputs_inference])\n",
    "        decoder_concat_input_inference = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs_inference, attention_output_inference])\n",
    "        \n",
    "        decoder_outputs_final_inference = decoder_dense(decoder_concat_input_inference)\n",
    "\n",
    "        decoder_model = Model(\n",
    "            [decoder_inputs, encoder_outputs_inference] + decoder_states_inputs,\n",
    "            [decoder_outputs_final_inference] + decoder_states_inference\n",
    "        )\n",
    "\n",
    "        # Store models in WandB for later use if needed, or save them locally.\n",
    "        # wandb.save doesn't directly save Keras models, but their artifacts.\n",
    "        # For full model saving, it's better to save locally and then upload as artifact if desired.\n",
    "\n",
    "# --- WandB Sweep Configuration ---\n",
    "sweep_config = {\n",
    "    'method': 'random', # or 'grid', 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embedding_dim': {\n",
    "            'values': [16, 32, 64, 128]\n",
    "        },\n",
    "        'hidden_units': {\n",
    "            'values': [64, 128, 256, 512]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['LSTM', 'GRU'] # RNN can be too slow/perform poorly for seq2seq\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'values': [0.2, 0.3, 0.4]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-4,\n",
    "            'max': 1e-2\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 8\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DA_seq2seq_transliteration\")\n",
    "wandb.agent(sweep_id, train_attention_model, count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T16:11:01.868870Z",
     "iopub.status.busy": "2025-05-20T16:11:01.868607Z",
     "iopub.status.idle": "2025-05-20T16:11:20.208085Z",
     "shell.execute_reply": "2025-05-20T16:11:20.207445Z",
     "shell.execute_reply.started": "2025-05-20T16:11:01.868850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: q65a5akg\n",
      "Sweep URL: https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/q65a5akg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: clx1kfgi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_units: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003672846792307083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DA6401_Assignment3_Attention_Fix' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-23 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_35/1701304297.py\", line 15, in train_attention_model\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1544, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1530, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 799, in init\n",
      "    wandb.run.finish()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 4238, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9865p5f7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_units: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002884179089578507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DA6401_Assignment3_Attention_Fix' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-24 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_35/1701304297.py\", line 15, in train_attention_model\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1544, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1530, in init\n",
      "    return wi.init(run_settings, run_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 799, in init\n",
      "    wandb.run.finish()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 4238, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 483, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 425, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2182, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 387, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2190, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 783, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 796, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 60, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_sock.py\", line 39, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 174, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Assume these are defined globally or passed into the function\n",
    "# For demonstration, let's set some dummy values\n",
    "num_encoder_tokens = 100\n",
    "num_decoder_tokens = 100\n",
    "max_encoder_seq_length = 50\n",
    "max_decoder_seq_length = 21 # This seems to be the '21' from your error\n",
    "# And dummy data (replace with your actual loaded data)\n",
    "encoder_input_data = np.random.randint(0, num_encoder_tokens, size=(100, max_encoder_seq_length))\n",
    "decoder_input_data = np.random.randint(0, num_decoder_tokens, size=(100, max_decoder_seq_length))\n",
    "# One-hot encode decoder target data for categorical_crossentropy\n",
    "decoder_target_data = tf.keras.utils.to_categorical(np.random.randint(0, num_decoder_tokens, size=(100, max_decoder_seq_length)), num_classes=num_decoder_tokens)\n",
    "\n",
    "\n",
    "def train_attention_model(config=None):\n",
    "    with wandb.init(config=config, project=\"DA6401_Assignment3_Attention_Fix\"):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Define model parameters from config\n",
    "        embedding_dim = config.embedding_dim\n",
    "        hidden_units = config.hidden_units\n",
    "        cell_type = config.cell_type\n",
    "        dropout_rate = config.dropout_rate\n",
    "        learning_rate = config.learning_rate\n",
    "\n",
    "        # Choose the RNN cell based on config\n",
    "        if cell_type == 'LSTM':\n",
    "            rnn_cell = LSTM\n",
    "        elif cell_type == 'GRU':\n",
    "            rnn_cell = GRU\n",
    "        else:\n",
    "            rnn_cell = SimpleRNN\n",
    "\n",
    "        # --- Encoder ---\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_input') # None for variable length sequences\n",
    "        encoder_embedding = Embedding(num_encoder_tokens, embedding_dim)(encoder_inputs)\n",
    "        # return_sequences=True is critical for attention, as we need all hidden states\n",
    "        encoder_rnn = rnn_cell(hidden_units, return_sequences=True, return_state=True, dropout=dropout_rate, name='encoder_rnn')\n",
    "        encoder_outputs, state_h, state_c = encoder_rnn(encoder_embedding) # state_c will be None for GRU/SimpleRNN\n",
    "\n",
    "        encoder_states = [state_h, state_c] if cell_type == 'LSTM' else [state_h]\n",
    "\n",
    "        # --- Decoder ---\n",
    "        decoder_inputs = Input(shape=(None,), name='decoder_input') # None for variable length sequences\n",
    "        decoder_embedding = Embedding(num_decoder_tokens, embedding_dim)(decoder_inputs)\n",
    "        decoder_rnn = rnn_cell(hidden_units, return_sequences=True, return_state=True, dropout=dropout_rate, name='decoder_rnn')\n",
    "\n",
    "        # The decoder is initialized with the encoder's last state\n",
    "        # The `decoder_outputs_sequence` are the hidden states of the decoder at each time step.\n",
    "        decoder_outputs_sequence, _, _ = decoder_rnn(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "        # --- Attention Layer ---\n",
    "        # The query comes from the decoder (current decoder hidden states)\n",
    "        # The value and key come from the encoder (all encoder hidden states)\n",
    "        attention_layer = tf.keras.layers.Attention()\n",
    "        attention_output = attention_layer([decoder_outputs_sequence, encoder_outputs])\n",
    "\n",
    "        # --- Concatenation ---\n",
    "        # Concatenate the attention output (context vector) with the decoder's hidden states\n",
    "        # Both `decoder_outputs_sequence` and `attention_output` should have the same\n",
    "        # sequence length (max_decoder_seq_length) and batch size.\n",
    "        # The last dimension (feature dimension) can be different, as concat will stack them.\n",
    "        decoder_concat_input = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs_sequence, attention_output])\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # TimeDistributed Dense layer to predict a character at each time step\n",
    "        decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation='softmax', name='decoder_output'))\n",
    "        decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "        # Define the model\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        # Callbacks\n",
    "        callbacks = [WandbCallback()]\n",
    "\n",
    "        # Train the model (assuming you have train/validation data prepared)\n",
    "        model.fit(\n",
    "            [encoder_input_data, decoder_input_data], # Use your actual train data here\n",
    "            decoder_target_data,                      # Use your actual train target here\n",
    "            batch_size=config.batch_size,\n",
    "            epochs=config.epochs,\n",
    "            validation_split=0.2, # Or use your explicit validation set\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # --- Save the best model ---\n",
    "        model.save(f\"best_attention_model_{wandb.run.name}.h5\")\n",
    "\n",
    "        # --- Inference setup (for prediction later) ---\n",
    "        # Encoder model for inference\n",
    "        encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
    "\n",
    "        # Decoder model for inference (needs to take encoder outputs and previous decoder state)\n",
    "        # We need the encoder_outputs to compute attention at each decoding step.\n",
    "        decoder_state_input_h = Input(shape=(hidden_units,), name='decoder_h_input')\n",
    "        decoder_state_input_c = Input(shape=(hidden_units,), name='decoder_c_input') if cell_type == 'LSTM' else None\n",
    "        \n",
    "        # Input for the previous character predicted by the decoder\n",
    "        decoder_single_input = Input(shape=(1,), name='decoder_single_input')\n",
    "        decoder_single_embedding = Embedding(num_decoder_tokens, embedding_dim)(decoder_single_input)\n",
    "\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] if cell_type == 'LSTM' else [decoder_state_input_h]\n",
    "        \n",
    "        # Pass the single time step input and initial states to the decoder RNN\n",
    "        decoder_outputs_inference, state_h_inference, state_c_inference = decoder_rnn(\n",
    "            decoder_single_embedding, initial_state=decoder_states_inputs\n",
    "        )\n",
    "        decoder_states_inference = [state_h_inference, state_c_inference] if cell_type == 'LSTM' else [state_h_inference]\n",
    "\n",
    "        # Input for encoder_outputs to the decoder inference model\n",
    "        encoder_outputs_inference = Input(shape=(max_encoder_seq_length, hidden_units,), name='encoder_outputs_inference_input')\n",
    "\n",
    "        # Attention for inference: query is current decoder output, key/value are all encoder outputs\n",
    "        attention_output_inference = attention_layer([decoder_outputs_inference, encoder_outputs_inference])\n",
    "\n",
    "        # Concatenate for inference\n",
    "        decoder_concat_input_inference = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs_inference, attention_output_inference])\n",
    "        \n",
    "        # Output probability distribution for the next character\n",
    "        decoder_outputs_final_inference = decoder_dense(decoder_concat_input_inference)\n",
    "\n",
    "        decoder_model = Model(\n",
    "            [decoder_single_input, encoder_outputs_inference] + decoder_states_inputs,\n",
    "            [decoder_outputs_final_inference] + decoder_states_inference\n",
    "        )\n",
    "\n",
    "\n",
    "# --- WandB Sweep Configuration (example) ---\n",
    "sweep_config = {\n",
    "    'method': 'random', # or 'grid', 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embedding_dim': {\n",
    "            'values': [16, 32, 64]\n",
    "        },\n",
    "        'hidden_units': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['LSTM', 'GRU']\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'values': [0.2, 0.3]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-4,\n",
    "            'max': 1e-3\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 8\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DA_seq2seq_transliteration\")\n",
    "wandb.agent(sweep_id, train_attention_model, count=2) # Run a few experiments for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T16:34:58.240081Z",
     "iopub.status.busy": "2025-05-20T16:34:58.239607Z",
     "iopub.status.idle": "2025-05-20T16:34:58.267850Z",
     "shell.execute_reply": "2025-05-20T16:34:58.267211Z",
     "shell.execute_reply.started": "2025-05-20T16:34:58.240058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RNNConnectivityVisualizer:\n",
    "    \"\"\"\n",
    "    A class to visualize the connectivity between input and output in an RNN-based seq2seq model.\n",
    "    This helps to understand which input characters the model is \"looking at\" when decoding each\n",
    "    output character.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer_src, tokenizer_tgt):\n",
    "        \"\"\"\n",
    "        Initialize the visualizer with the trained model and tokenizers\n",
    "        \n",
    "        Args:\n",
    "            model: The trained seq2seq model\n",
    "            tokenizer_src: Tokenizer for the source language (Latin script)\n",
    "            tokenizer_tgt: Tokenizer for the target language (Devanagari script)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        \n",
    "        # Create a model that outputs the hidden states\n",
    "        self.extract_hidden_states()\n",
    "        \n",
    "    def extract_hidden_states(self):\n",
    "        \"\"\"\n",
    "        Create a model that can extract hidden states from the encoder and decoder\n",
    "        \"\"\"\n",
    "        # This implementation will depend on your model architecture\n",
    "        # For a typical Keras seq2seq model:\n",
    "        \n",
    "        # Find the encoder layer\n",
    "        encoder_layer = None\n",
    "        decoder_layer = None\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if 'encoder' in layer.name.lower():\n",
    "                encoder_layer = layer\n",
    "            if 'decoder' in layer.name.lower():\n",
    "                decoder_layer = layer\n",
    "        \n",
    "        if encoder_layer is None or decoder_layer is None:\n",
    "            raise ValueError(\"Could not find encoder or decoder layer in the model\")\n",
    "        \n",
    "        # Create a model that returns encoder hidden states\n",
    "        encoder_inputs = self.model.input[0] \n",
    "        encoder_outputs = encoder_layer.output\n",
    "        self.encoder_model = Model(inputs=encoder_inputs, outputs=encoder_outputs)\n",
    "        \n",
    "        # Create a model that returns decoder hidden states\n",
    "        # This is more complex and depends on your specific architecture\n",
    "        # For a typical seq2seq model with attention:\n",
    "        decoder_inputs = self.model.input[1] if len(self.model.input) > 1 else None\n",
    "        decoder_outputs = decoder_layer.output\n",
    "        self.decoder_model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                                  outputs=decoder_outputs)\n",
    "        \n",
    "    def compute_gradients(self, input_sequence, output_sequence):\n",
    "        \"\"\"\n",
    "        Compute gradients of the output with respect to the hidden states\n",
    "        \n",
    "        Args:\n",
    "            input_sequence: A tokenized input sequence\n",
    "            output_sequence: A tokenized output sequence\n",
    "            \n",
    "        Returns:\n",
    "            A matrix of gradients showing the influence of each input on each output\n",
    "        \"\"\"\n",
    "        # Convert sequences to proper format\n",
    "        input_seq = np.array([input_sequence])\n",
    "        \n",
    "        # Define a function to compute gradients\n",
    "        # This is a simplified version and may need to be adapted to your specific model\n",
    "        @tf.function\n",
    "        def get_gradients(inputs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Get encoder states\n",
    "                encoder_states = self.encoder_model(inputs)\n",
    "                # Make it watchable for gradient calculation\n",
    "                tape.watch(encoder_states)\n",
    "                \n",
    "                # Pass to decoder and get outputs\n",
    "                # This will need to be adapted to your model architecture\n",
    "                if isinstance(encoder_states, list):\n",
    "                    hidden_states = encoder_states[0]  # Assuming first output is hidden states\n",
    "                else:\n",
    "                    hidden_states = encoder_states\n",
    "                    \n",
    "                # Use decoder to get predictions\n",
    "                # This is simplified and needs to match your decoder architecture\n",
    "                predictions = self.decoder_model([inputs, hidden_states])\n",
    "                \n",
    "                return predictions, tape.gradient(predictions, hidden_states)\n",
    "        \n",
    "        # Get outputs and gradients\n",
    "        predictions, gradients = get_gradients(input_seq)\n",
    "        \n",
    "        # Process the gradients to get connectivity matrix\n",
    "        # Take absolute values since we care about magnitude of influence\n",
    "        connectivity_matrix = np.abs(gradients.numpy())\n",
    "        \n",
    "        return connectivity_matrix, predictions.numpy()\n",
    "    \n",
    "    def _alternative_compute_connectivity(self, input_sequence, output_sequence):\n",
    "        \"\"\"\n",
    "        An alternative approach to compute connectivity based on correlation of activations\n",
    "        \n",
    "        Args:\n",
    "            input_sequence: A tokenized input sequence\n",
    "            output_sequence: A tokenized output sequence\n",
    "            \n",
    "        Returns:\n",
    "            A matrix showing the connectivity between inputs and outputs\n",
    "        \"\"\"\n",
    "        # Convert sequences to proper format\n",
    "        input_seq = np.array([input_sequence])\n",
    "        output_seq = np.array([output_sequence])\n",
    "        \n",
    "        # Get encoder hidden states\n",
    "        encoder_states = self.encoder_model.predict(input_seq)\n",
    "        \n",
    "        # Create a model to get decoder hidden states at each step\n",
    "        # This depends on your model architecture\n",
    "        \n",
    "        # Initialize connectivity matrix\n",
    "        input_len = len(input_sequence)\n",
    "        output_len = len(output_sequence)\n",
    "        connectivity = np.zeros((output_len, input_len))\n",
    "        \n",
    "        # For each output position\n",
    "        for i in range(output_len):\n",
    "            # Get decoder state at this position\n",
    "            decoder_input = output_seq[:, :i+1]\n",
    "            decoder_state = self.decoder_model.predict([input_seq, decoder_input])\n",
    "            \n",
    "            # Compare with each encoder hidden state\n",
    "            for j in range(input_len):\n",
    "                # Compute correlation or cosine similarity\n",
    "                encoder_state_j = encoder_states[0, j, :]\n",
    "                if isinstance(decoder_state, list):\n",
    "                    decoder_state_i = decoder_state[0][0, -1, :]  # Last timestep\n",
    "                else:\n",
    "                    decoder_state_i = decoder_state[0, -1, :]\n",
    "                \n",
    "                # Compute correlation\n",
    "                correlation = np.corrcoef(encoder_state_j, decoder_state_i)[0, 1]\n",
    "                connectivity[i, j] = np.abs(correlation)\n",
    "        \n",
    "        return connectivity\n",
    "    \n",
    "    def visualize_connectivity(self, input_text, target_text, method='perturbation'):\n",
    "        \"\"\"\n",
    "        Visualize the connectivity between input and output characters\n",
    "        \n",
    "        Args:\n",
    "            input_text: Input text in Latin script\n",
    "            target_text: Target text in Devanagari script\n",
    "            method: Method to compute connectivity ('gradient', 'correlation', or 'perturbation')\n",
    "            \n",
    "        Returns:\n",
    "            A matplotlib figure showing the connectivity heatmap\n",
    "        \"\"\"\n",
    "        # Tokenize input and target\n",
    "        input_sequence = [self.tokenizer_src.word_index.get(char, 1) for char in input_text]\n",
    "        target_sequence = [self.tokenizer_tgt.word_index.get(char, 1) for char in target_text]\n",
    "        \n",
    "        if method == 'gradient':\n",
    "            connectivity, _ = self.compute_gradients(input_sequence, target_sequence)\n",
    "        elif method == 'correlation':\n",
    "            connectivity = self._alternative_compute_connectivity(input_sequence, target_sequence)\n",
    "        elif method == 'perturbation':\n",
    "            connectivity = self._compute_perturbation_connectivity(input_text, target_text)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        # Create a heatmap visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(connectivity, \n",
    "                         xticklabels=list(input_text),\n",
    "                         yticklabels=list(target_text), \n",
    "                         cmap='viridis')\n",
    "        \n",
    "        # Add labels\n",
    "        plt.xlabel('Input Characters (Latin)')\n",
    "        plt.ylabel('Output Characters (Devanagari)')\n",
    "        plt.title(f'Character Connectivity: \"{input_text}\" → \"{target_text}\"')\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.gcf()\n",
    "    \n",
    "    def _compute_perturbation_connectivity(self, input_text, target_text):\n",
    "        \"\"\"\n",
    "        Compute connectivity using perturbation analysis\n",
    "        This method is often more reliable than gradient analysis for complex models\n",
    "        \n",
    "        Args:\n",
    "            input_text: Input text in Latin script\n",
    "            target_text: Target text in Devanagari script\n",
    "            \n",
    "        Returns:\n",
    "            A matrix showing the connectivity between inputs and outputs\n",
    "        \"\"\"\n",
    "        # Tokenize input and convert to model input format\n",
    "        input_sequence = np.array([[self.tokenizer_src.word_index.get(char, 1) for char in input_text]])\n",
    "        \n",
    "        # Get the baseline prediction\n",
    "        baseline_prediction = self.model.predict(input_sequence)[0]\n",
    "        \n",
    "        # Initialize connectivity matrix\n",
    "        connectivity = np.zeros((len(target_text), len(input_text)))\n",
    "        \n",
    "        # For each input character\n",
    "        for i in range(len(input_text)):\n",
    "            # Make a copy of the input with this character masked\n",
    "            perturbed_input = input_sequence.copy()\n",
    "            original_value = perturbed_input[0, i]\n",
    "            perturbed_input[0, i] = 0  # Mask with padding token or another special token\n",
    "            \n",
    "            # Get prediction with the perturbed input\n",
    "            perturbed_prediction = self.model.predict(perturbed_input)[0]\n",
    "            \n",
    "            # Measure the difference in predictions for each output position\n",
    "            for j in range(len(target_text)):\n",
    "                if j < len(baseline_prediction) and j < len(perturbed_prediction):\n",
    "                    # Compute the difference (various metrics possible)\n",
    "                    diff = np.abs(baseline_prediction[j] - perturbed_prediction[j])\n",
    "                    connectivity[j, i] = np.sum(diff)\n",
    "            \n",
    "            # Restore the original value\n",
    "            perturbed_input[0, i] = original_value\n",
    "        \n",
    "        # Normalize the connectivity matrix\n",
    "        connectivity = connectivity / np.max(connectivity)\n",
    "        \n",
    "        return connectivity\n",
    "        \n",
    "    def visualize_batch(self, test_pairs, num_samples=9, method='perturbation'):\n",
    "        \"\"\"\n",
    "        Create a grid of connectivity visualizations for multiple test examples\n",
    "        \n",
    "        Args:\n",
    "            test_pairs: List of (input_text, target_text) pairs\n",
    "            num_samples: Number of samples to visualize\n",
    "            method: Method to compute connectivity\n",
    "            \n",
    "        Returns:\n",
    "            A matplotlib figure with a grid of connectivity visualizations\n",
    "        \"\"\"\n",
    "        # Limit to the requested number of samples\n",
    "        samples = min(num_samples, len(test_pairs))\n",
    "        \n",
    "        # Create a grid layout\n",
    "        rows = int(np.ceil(np.sqrt(samples)))\n",
    "        cols = int(np.ceil(samples / rows))\n",
    "        \n",
    "        fig = plt.figure(figsize=(5*cols, 4*rows))\n",
    "        \n",
    "        # Generate each subplot\n",
    "        for i in range(samples):\n",
    "            input_text, target_text = test_pairs[i]\n",
    "            \n",
    "            plt.subplot(rows, cols, i+1)\n",
    "            \n",
    "            # Compute connectivity\n",
    "            if method == 'gradient':\n",
    "                input_sequence = [self.tokenizer_src.word_index.get(char, 1) for char in input_text]\n",
    "                target_sequence = [self.tokenizer_tgt.word_index.get(char, 1) for char in target_text]\n",
    "                connectivity, _ = self.compute_gradients(input_sequence, target_sequence)\n",
    "            elif method == 'correlation':\n",
    "                connectivity = self._alternative_compute_connectivity(input_text, target_text)\n",
    "            elif method == 'perturbation':\n",
    "                connectivity = self._compute_perturbation_connectivity(input_text, target_text)\n",
    "            \n",
    "            # Create heatmap\n",
    "            sns.heatmap(connectivity, \n",
    "                       xticklabels=list(input_text),\n",
    "                       yticklabels=list(target_text), \n",
    "                       cmap='viridis')\n",
    "            \n",
    "            plt.title(f'Example {i+1}: {input_text} → {target_text}')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def log_to_wandb(self, test_data, num_examples=9):\n",
    "        \"\"\"\n",
    "        Log connectivity visualizations to wandb\n",
    "        \n",
    "        Args:\n",
    "            test_data: List of (input_text, target_text) pairs from test set\n",
    "            num_examples: Number of examples to visualize\n",
    "        \"\"\"\n",
    "        # Initialize wandb if not already done\n",
    "        if wandb.run is None:\n",
    "            wandb.init(project=\"seq2seq-connectivity\")\n",
    "        \n",
    "        # Select examples from test data\n",
    "        selected_examples = test_data[:num_examples]\n",
    "        \n",
    "        # Create a grid visualization\n",
    "        fig = self.visualize_batch(selected_examples, num_samples=num_examples)\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log({\"connectivity_grid\": wandb.Image(fig)})\n",
    "        \n",
    "        # Log individual examples\n",
    "        for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "            fig = self.visualize_connectivity(input_text, target_text)\n",
    "            wandb.log({f\"connectivity_example_{i}\": wandb.Image(fig)})\n",
    "            plt.close(fig)\n",
    "        \n",
    "        # Log a table with examples and their connectivity scores\n",
    "        connectivity_data = []\n",
    "        for input_text, target_text in selected_examples:\n",
    "            connectivity = self._compute_perturbation_connectivity(input_text, target_text)\n",
    "            avg_connectivity = np.mean(connectivity)\n",
    "            max_connectivity = np.max(connectivity)\n",
    "            \n",
    "            connectivity_data.append([input_text, target_text, avg_connectivity, max_connectivity])\n",
    "        \n",
    "        table = wandb.Table(columns=[\"Input\", \"Target\", \"Avg Connectivity\", \"Max Connectivity\"],\n",
    "                           data=connectivity_data)\n",
    "        wandb.log({\"connectivity_stats\": table})\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# This would typically be used after training your seq2seq model\n",
    "\n",
    "def analyze_model_connectivity(trained_model, tokenizer_src, tokenizer_tgt, test_data):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the connectivity in a trained seq2seq model\n",
    "    \n",
    "    Args:\n",
    "        trained_model: The trained seq2seq model\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        tokenizer_tgt: Tokenizer for target language\n",
    "        test_data: List of (input_text, target_text) pairs from test set\n",
    "    \"\"\"\n",
    "    # Initialize the visualizer\n",
    "    visualizer = RNNConnectivityVisualizer(trained_model, tokenizer_src, tokenizer_tgt)\n",
    "    \n",
    "    # Log visualizations to wandb\n",
    "    visualizer.log_to_wandb(test_data)\n",
    "    \n",
    "    # Save some examples locally\n",
    "    fig = visualizer.visualize_batch(test_data[:9])\n",
    "    fig.savefig('connectivity_grid.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Create a 3x3 grid specifically for the assignment requirement\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            idx = i * 3 + j\n",
    "            if idx < len(test_data):\n",
    "                input_text, target_text = test_data[idx]\n",
    "                connectivity = visualizer._compute_perturbation_connectivity(input_text, target_text)\n",
    "                \n",
    "                ax = axes[i, j]\n",
    "                sns.heatmap(connectivity, \n",
    "                           xticklabels=list(input_text),\n",
    "                           yticklabels=list(target_text), \n",
    "                           cmap='viridis', \n",
    "                           ax=ax)\n",
    "                \n",
    "                ax.set_title(f'{input_text} → {target_text}')\n",
    "                ax.set_xlabel('Input Characters (Latin)')\n",
    "                ax.set_ylabel('Output Characters (Devanagari)')\n",
    "                plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig('connectivity_grid_3x3.png')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T16:34:58.789137Z",
     "iopub.status.busy": "2025-05-20T16:34:58.788891Z",
     "iopub.status.idle": "2025-05-20T16:34:58.827194Z",
     "shell.execute_reply": "2025-05-20T16:34:58.826169Z",
     "shell.execute_reply.started": "2025-05-20T16:34:58.789119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_visualization_model(seq2seq_model):\n",
    "    \"\"\"\n",
    "    Creates a model for extracting hidden states from a trained seq2seq model.\n",
    "    \n",
    "    Args:\n",
    "        seq2seq_model: The trained sequence-to-sequence model\n",
    "        \n",
    "    Returns:\n",
    "        encoder_model: Model that outputs encoder hidden states\n",
    "        decoder_model: Model that outputs decoder hidden states at each step\n",
    "    \"\"\"\n",
    "    # Find encoder and decoder layers\n",
    "    encoder = None\n",
    "    decoder = None\n",
    "    \n",
    "    for layer in seq2seq_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.RNN) and 'encoder' in layer.name:\n",
    "            encoder = layer\n",
    "        elif isinstance(layer, tf.keras.layers.RNN) and 'decoder' in layer.name:\n",
    "            decoder = layer\n",
    "    \n",
    "    if encoder is None or decoder is None:\n",
    "        # Try to find layers by name if the above didn't work\n",
    "        for layer in seq2seq_model.layers:\n",
    "            if 'encoder' in layer.name.lower():\n",
    "                encoder = layer\n",
    "            elif 'decoder' in layer.name.lower():\n",
    "                decoder = layer\n",
    "    \n",
    "    if encoder is None or decoder is None:\n",
    "        raise ValueError(\"Could not find encoder and decoder layers in the model\")\n",
    "    \n",
    "    # Get encoder inputs and outputs\n",
    "    encoder_inputs = seq2seq_model.input[0] if isinstance(seq2seq_model.input, list) else seq2seq_model.input\n",
    "    encoder_outputs = encoder.output\n",
    "    \n",
    "    # Create encoder model\n",
    "    encoder_model = Model(inputs=encoder_inputs, outputs=encoder_outputs, name='encoder_model')\n",
    "    \n",
    "    # For the decoder, we need the initial state and the input\n",
    "    # This will vary based on your model architecture, so adjust as needed\n",
    "    \n",
    "    # Create decoder model to get states at each timestep\n",
    "    # This is a simplified example - adjust to match your architecture\n",
    "    if hasattr(seq2seq_model, 'layers') and any('decoder_input' in layer.name for layer in seq2seq_model.layers):\n",
    "        decoder_inputs = [layer.input for layer in seq2seq_model.layers if 'decoder_input' in layer.name][0]\n",
    "    else:\n",
    "        # Fallback: get the second input if model has multiple inputs\n",
    "        decoder_inputs = seq2seq_model.input[1] if isinstance(seq2seq_model.input, list) and len(seq2seq_model.input) > 1 else None\n",
    "    \n",
    "    if decoder_inputs is None:\n",
    "        # If we still don't have decoder inputs, create a placeholder\n",
    "        # with the same shape as decoder would expect\n",
    "        vocab_size = encoder_inputs.shape[-1] if hasattr(encoder_inputs, 'shape') else None\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=(None, vocab_size), name='decoder_inputs')\n",
    "    \n",
    "    # Get decoder outputs\n",
    "    decoder_outputs = decoder.output\n",
    "    \n",
    "    # Create decoder model\n",
    "    decoder_model = Model(\n",
    "        inputs=[encoder_inputs, decoder_inputs] if decoder_inputs is not None else encoder_inputs,\n",
    "        outputs=decoder_outputs,\n",
    "        name='decoder_model'\n",
    "    )\n",
    "    \n",
    "    return encoder_model, decoder_model\n",
    "\n",
    "def compute_connectivity_matrix(model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text):\n",
    "    \"\"\"\n",
    "    Computes a connectivity matrix showing which input character the model is focusing on\n",
    "    when producing each output character.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained seq2seq model\n",
    "        encoder_model: Model that outputs encoder hidden states\n",
    "        tokenizer_src: Tokenizer for the source language\n",
    "        tokenizer_tgt: Tokenizer for the target language\n",
    "        input_text: Input text in Latin script\n",
    "        target_text: Target text in Devanagari script\n",
    "        \n",
    "    Returns:\n",
    "        connectivity: A matrix of shape (output_length, input_length) showing the\n",
    "                      influence of each input character on each output character\n",
    "    \"\"\"\n",
    "    # Tokenize input\n",
    "    input_seq = np.array([[tokenizer_src.word_index.get(char, 1) for char in input_text]])\n",
    "    \n",
    "    # Get encoder states for the input sequence\n",
    "    encoder_states = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # We'll use perturbation analysis to measure how each input affects each output\n",
    "    connectivity = np.zeros((len(target_text), len(input_text)))\n",
    "    \n",
    "    # Get baseline prediction\n",
    "    baseline_pred = model.predict(input_seq)\n",
    "    if isinstance(baseline_pred, list):\n",
    "        baseline_pred = baseline_pred[0]  # Take first output if multiple outputs\n",
    "    \n",
    "    # For each input character position\n",
    "    for i in range(len(input_text)):\n",
    "        # Create perturbed input by masking this character\n",
    "        perturbed_input = input_seq.copy()\n",
    "        original_value = perturbed_input[0, i]\n",
    "        \n",
    "        # Replace with padding token (usually 0) or OOV token\n",
    "        perturbed_input[0, i] = 0\n",
    "        \n",
    "        # Get prediction with the perturbed input\n",
    "        perturbed_pred = model.predict(perturbed_input)\n",
    "        if isinstance(perturbed_pred, list):\n",
    "            perturbed_pred = perturbed_pred[0]\n",
    "        \n",
    "        # Measure effect on each output position\n",
    "        # (Only consider positions up to the target length)\n",
    "        max_len = min(len(target_text), baseline_pred.shape[1], perturbed_pred.shape[1])\n",
    "        \n",
    "        for j in range(max_len):\n",
    "            # Calculate difference in prediction probabilities\n",
    "            diff = np.sum(np.abs(baseline_pred[0, j] - perturbed_pred[0, j]))\n",
    "            connectivity[j, i] = diff\n",
    "        \n",
    "        # Restore original value\n",
    "        perturbed_input[0, i] = original_value\n",
    "    \n",
    "    # Normalize connectivity scores\n",
    "    if np.max(connectivity) > 0:\n",
    "        connectivity = connectivity / np.max(connectivity)\n",
    "    \n",
    "    return connectivity\n",
    "\n",
    "def visualize_connectivity(connectivity, input_text, target_text, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Visualizes the connectivity matrix as a heatmap.\n",
    "    \n",
    "    Args:\n",
    "        connectivity: The connectivity matrix\n",
    "        input_text: Input text in Latin script\n",
    "        target_text: Target text in Devanagari script\n",
    "        figsize: Figure size\n",
    "        \n",
    "    Returns:\n",
    "        fig: The matplotlib figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(connectivity, \n",
    "               xticklabels=list(input_text),\n",
    "               yticklabels=list(target_text),\n",
    "               cmap='viridis',\n",
    "               ax=ax)\n",
    "    \n",
    "    # Add labels\n",
    "    ax.set_xlabel('Input Characters (Latin)')\n",
    "    ax.set_ylabel('Output Characters (Devanagari)')\n",
    "    ax.set_title(f'Character Connectivity: \"{input_text}\" → \"{target_text}\"')\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_connectivity_grid(model, encoder_model, test_data, tokenizer_src, tokenizer_tgt, rows=3, cols=3):\n",
    "    \"\"\"\n",
    "    Creates a grid of connectivity visualizations for multiple test examples.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained seq2seq model\n",
    "        encoder_model: Model that outputs encoder hidden states\n",
    "        test_data: List of (input_text, target_text) pairs\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        tokenizer_tgt: Tokenizer for target language\n",
    "        rows: Number of rows in the grid\n",
    "        cols: Number of columns in the grid\n",
    "        \n",
    "    Returns:\n",
    "        fig: The matplotlib figure with the grid\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    samples = min(rows*cols, len(test_data))\n",
    "    \n",
    "    for i in range(samples):\n",
    "        input_text, target_text = test_data[i]\n",
    "        \n",
    "        # Compute connectivity\n",
    "        connectivity = compute_connectivity_matrix(\n",
    "            model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "        )\n",
    "        \n",
    "        # Create heatmap in the corresponding subplot\n",
    "        sns.heatmap(connectivity,\n",
    "                   xticklabels=list(input_text),\n",
    "                   yticklabels=list(target_text),\n",
    "                   cmap='viridis',\n",
    "                   ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(f'{input_text} → {target_text}')\n",
    "        axes[i].set_xlabel('Input (Latin)')\n",
    "        axes[i].set_ylabel('Output (Devanagari)')\n",
    "        plt.setp(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def log_connectivity_to_wandb(model, test_data, tokenizer_src, tokenizer_tgt, run_name=\"connectivity-visualization\"):\n",
    "    \"\"\"\n",
    "    Analyzes model connectivity and logs results to W&B.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained seq2seq model\n",
    "        test_data: List of (input_text, target_text) pairs\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        tokenizer_tgt: Tokenizer for target language\n",
    "        run_name: Name for the W&B run\n",
    "    \"\"\"\n",
    "    # Initialize W&B run\n",
    "    wandb.init(project=\"DA_seq2seq_transliteration\", name=run_name)\n",
    "    \n",
    "    # Create visualization models\n",
    "    encoder_model, decoder_model = setup_visualization_model(model)\n",
    "    \n",
    "    # Select examples from test data\n",
    "    selected_examples = test_data[:9]  # For a 3x3 grid\n",
    "    \n",
    "    # Create and log individual connectivity visualizations\n",
    "    for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "        connectivity = compute_connectivity_matrix(\n",
    "            model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "        )\n",
    "        \n",
    "        fig = visualize_connectivity(connectivity, input_text, target_text)\n",
    "        wandb.log({f\"connectivity_example_{i+1}\": wandb.Image(fig)})\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Create and log grid visualization\n",
    "    grid_fig = create_connectivity_grid(\n",
    "        model, encoder_model, selected_examples, tokenizer_src, tokenizer_tgt\n",
    "    )\n",
    "    \n",
    "    wandb.log({\"connectivity_grid\": wandb.Image(grid_fig)})\n",
    "    \n",
    "    # Save grid locally\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    grid_fig.savefig(\"visualizations/connectivity_grid.png\")\n",
    "    plt.close(grid_fig)\n",
    "    \n",
    "    # Log configuration\n",
    "    wandb.config.update({\n",
    "        \"visualization_type\": \"connectivity\",\n",
    "        \"num_examples\": len(selected_examples)\n",
    "    })\n",
    "    \n",
    "    # Create a table of connectivity statistics\n",
    "    stats_data = []\n",
    "    for input_text, target_text in selected_examples:\n",
    "        connectivity = compute_connectivity_matrix(\n",
    "            model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "        )\n",
    "        \n",
    "        # Calculate statistics\n",
    "        max_conn = np.max(connectivity)\n",
    "        avg_conn = np.mean(connectivity)\n",
    "        std_conn = np.std(connectivity)\n",
    "        \n",
    "        # Find position of maximum connectivity\n",
    "        max_pos = np.unravel_index(np.argmax(connectivity), connectivity.shape)\n",
    "        max_out_char = target_text[max_pos[0]] if max_pos[0] < len(target_text) else \"N/A\"\n",
    "        max_in_char = input_text[max_pos[1]] if max_pos[1] < len(input_text) else \"N/A\"\n",
    "        \n",
    "        stats_data.append([\n",
    "            input_text, target_text, \n",
    "            float(max_conn), float(avg_conn), float(std_conn),\n",
    "            f\"{max_out_char} (out) <-> {max_in_char} (in)\"\n",
    "        ])\n",
    "    \n",
    "    # Create and log W&B table\n",
    "    columns = [\"Input\", \"Target\", \"Max Connectivity\", \"Avg Connectivity\", \n",
    "               \"Std Connectivity\", \"Max Connection\"]\n",
    "    \n",
    "    connectivity_table = wandb.Table(columns=columns, data=stats_data)\n",
    "    wandb.log({\"connectivity_stats\": connectivity_table})\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return grid_fig\n",
    "\n",
    "\n",
    "# Main execution code for Question 6\n",
    "def run_connectivity_analysis(model_path, test_data_path, tokenizer_src_path, tokenizer_tgt_path):\n",
    "    \"\"\"\n",
    "    Run the connectivity analysis for Question 6\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model\n",
    "        test_data_path: Path to the test data\n",
    "        tokenizer_src_path: Path to the source tokenizer\n",
    "        tokenizer_tgt_path: Path to the target tokenizer\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load tokenizers\n",
    "    with open(tokenizer_src_path, 'rb') as f:\n",
    "        tokenizer_src = pickle.load(f)\n",
    "    \n",
    "    with open(tokenizer_tgt_path, 'rb') as f:\n",
    "        tokenizer_tgt = pickle.load(f)\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = []\n",
    "    with open(test_data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                latin, devanagari = parts\n",
    "                test_data.append((latin, devanagari))\n",
    "    \n",
    "    # Run connectivity analysis and log to W&B\n",
    "    grid_fig = log_connectivity_to_wandb(\n",
    "        model, test_data, tokenizer_src, tokenizer_tgt,\n",
    "        run_name=\"seq2seq-connectivity-analysis\"\n",
    "    )\n",
    "    \n",
    "    print(\"Connectivity analysis complete.\")\n",
    "    print(\"Results have been logged to W&B and saved locally in the 'visualizations' folder.\")\n",
    "    \n",
    "    return grid_fig\n",
    "\n",
    "\n",
    "# Example usage in a notebook or script:\n",
    "\"\"\"\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('path/to/your/best_model.h5')\n",
    "\n",
    "# Load your tokenizers\n",
    "import pickle\n",
    "with open('path/to/your/tokenizer_src.pickle', 'rb') as f:\n",
    "    tokenizer_src = pickle.load(f)\n",
    "    \n",
    "with open('path/to/your/tokenizer_tgt.pickle', 'rb') as f:\n",
    "    tokenizer_tgt = pickle.load(f)\n",
    "\n",
    "# Load your test data\n",
    "test_data = []\n",
    "with open('path/to/your/test_data.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            latin, devanagari = parts\n",
    "            test_data.append((latin, devanagari))\n",
    "\n",
    "# Run the connectivity analysis\n",
    "grid_fig = log_connectivity_to_wandb(model, test_data, tokenizer_src, tokenizer_tgt)\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Additional utility functions for extracting activations\n",
    "\n",
    "def extract_activations(model, layer_name, input_data):\n",
    "    \"\"\"\n",
    "    Extracts activations from a specific layer in the model.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        layer_name: Name of the layer to extract activations from\n",
    "        input_data: Input data to feed into the model\n",
    "        \n",
    "    Returns:\n",
    "        activations: The activations of the specified layer\n",
    "    \"\"\"\n",
    "    # Create a model that outputs the activations of the target layer\n",
    "    layer = None\n",
    "    for l in model.layers:\n",
    "        if layer_name in l.name:\n",
    "            layer = l\n",
    "            break\n",
    "    \n",
    "    if layer is None:\n",
    "        raise ValueError(f\"Layer {layer_name} not found in model\")\n",
    "    \n",
    "    activation_model = Model(inputs=model.input, outputs=layer.output)\n",
    "    activations = activation_model.predict(input_data)\n",
    "    \n",
    "    return activations\n",
    "\n",
    "def get_all_rnn_layers(model):\n",
    "    \"\"\"\n",
    "    Gets all RNN layers (RNN, LSTM, GRU) in the model.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        \n",
    "    Returns:\n",
    "        rnn_layers: List of RNN layer names\n",
    "    \"\"\"\n",
    "    rnn_layers = []\n",
    "    for layer in model.layers:\n",
    "        if any(t in layer.__class__.__name__ for t in ['RNN', 'LSTM', 'GRU']):\n",
    "            rnn_layers.append(layer.name)\n",
    "    \n",
    "    return rnn_layers\n",
    "\n",
    "# Alternative connectivity visualization using layer activations\n",
    "\n",
    "def visualize_layer_activations(model, input_text, tokenizer_src, layer_name=None):\n",
    "    \"\"\"\n",
    "    Visualizes activations in an RNN layer for a given input.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        input_text: Input text in Latin script\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        layer_name: Name of the layer to visualize (if None, will use first RNN layer)\n",
    "        \n",
    "    Returns:\n",
    "        fig: The matplotlib figure\n",
    "    \"\"\"\n",
    "    # Find RNN layer if not specified\n",
    "    if layer_name is None:\n",
    "        rnn_layers = get_all_rnn_layers(model)\n",
    "        if not rnn_layers:\n",
    "            raise ValueError(\"No RNN layers found in model\")\n",
    "        layer_name = rnn_layers[0]\n",
    "    \n",
    "    # Tokenize input\n",
    "    input_seq = np.array([[tokenizer_src.word_index.get(char, 1) for char in input_text]])\n",
    "    \n",
    "    # Get activations\n",
    "    activations = extract_activations(model, layer_name, input_seq)\n",
    "    \n",
    "    # Plot activations\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    if len(activations.shape) == 3:  # (batch_size, timesteps, units)\n",
    "        acts = activations[0]  # First (and only) sequence in batch\n",
    "        im = ax.imshow(acts.T, aspect='auto', cmap='viridis')\n",
    "        ax.set_xlabel('Input Characters')\n",
    "        ax.set_ylabel('Hidden Units')\n",
    "        ax.set_title(f'Activations in {layer_name} for \"{input_text}\"')\n",
    "        \n",
    "        # Add input characters as x-tick labels\n",
    "        ax.set_xticks(np.arange(len(input_text)))\n",
    "        ax.set_xticklabels(list(input_text), rotation=45, ha='right')\n",
    "        \n",
    "        fig.colorbar(im, ax=ax, label='Activation Value')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"Unexpected activation shape: {activations.shape}\", \n",
    "               ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def visualize_and_log_neuron_analysis(model, test_data, tokenizer_src, run_name=\"neuron-analysis\"):\n",
    "    \"\"\"\n",
    "    Performs a neuron-level analysis to see which neurons are most active for which inputs\n",
    "    and logs results to W&B.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained seq2seq model\n",
    "        test_data: List of (input_text, target_text) pairs\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        run_name: Name for the W&B run\n",
    "    \"\"\"\n",
    "    # Initialize W&B run\n",
    "    wandb.init(project=\"DA_seq2seq_transliteration\", name=run_name)\n",
    "    \n",
    "    # Find RNN layers\n",
    "    rnn_layers = get_all_rnn_layers(model)\n",
    "    if not rnn_layers:\n",
    "        print(\"No RNN layers found in model\")\n",
    "        return\n",
    "    \n",
    "    # Select the first RNN layer for analysis\n",
    "    target_layer = rnn_layers[0]\n",
    "    \n",
    "    # Select examples from test data\n",
    "    selected_examples = test_data[:5]  # Limit to a few examples\n",
    "    \n",
    "    for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "        # Visualize layer activations\n",
    "        act_fig = visualize_layer_activations(model, input_text, tokenizer_src, target_layer)\n",
    "        wandb.log({f\"activations_example_{i+1}\": wandb.Image(act_fig)})\n",
    "        plt.close(act_fig)\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "# Main function that combines multiple connectivity visualization approaches\n",
    "\n",
    "def comprehensive_connectivity_analysis(model, test_data, tokenizer_src, tokenizer_tgt, \n",
    "                                      output_dir=\"connectivity_visualizations\",\n",
    "                                      log_to_wandb=True):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive connectivity analysis using multiple approaches.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained seq2seq model\n",
    "        test_data: List of (input_text, target_text) pairs\n",
    "        tokenizer_src: Tokenizer for source language\n",
    "        tokenizer_tgt: Tokenizer for target language\n",
    "        output_dir: Directory to save visualization outputs\n",
    "        log_to_wandb: Whether to log results to W&B\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize W&B if requested\n",
    "    if log_to_wandb and wandb.run is None:\n",
    "        wandb.init(project=\"DA_seq2seq_transliteration\", name=\"comprehensive-connectivity\")\n",
    "    \n",
    "    # 1. Create encoder model for extracting hidden states\n",
    "    encoder_model, decoder_model = setup_visualization_model(model)\n",
    "    \n",
    "    # 2. Select examples (first 9 for a 3x3 grid)\n",
    "    selected_examples = test_data[:9]\n",
    "    \n",
    "    # 3. Perturbation-based connectivity analysis\n",
    "    grid_fig = create_connectivity_grid(\n",
    "        model, encoder_model, selected_examples, tokenizer_src, tokenizer_tgt\n",
    "    )\n",
    "    \n",
    "    # Save the grid\n",
    "    grid_path = os.path.join(output_dir, \"connectivity_grid.png\")\n",
    "    grid_fig.savefig(grid_path)\n",
    "    \n",
    "    if log_to_wandb:\n",
    "        wandb.log({\"connectivity_grid\": wandb.Image(grid_fig)})\n",
    "    \n",
    "    plt.close(grid_fig)\n",
    "    \n",
    "    # 4. Neuron activation analysis\n",
    "    for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "        # Get neuron activations\n",
    "        act_fig = visualize_layer_activations(model, input_text, tokenizer_src)\n",
    "        \n",
    "        # Save the figure\n",
    "        act_path = os.path.join(output_dir, f\"activations_example_{i+1}.png\")\n",
    "        act_fig.savefig(act_path)\n",
    "        \n",
    "        if log_to_wandb:\n",
    "            wandb.log({f\"activations_example_{i+1}\": wandb.Image(act_fig)})\n",
    "        \n",
    "        plt.close(act_fig)\n",
    "    \n",
    "    # 5. Visualize attention-like weights (even for non-attention models)\n",
    "    for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "        # Compute connectivity matrix\n",
    "        connectivity = compute_connectivity_matrix(\n",
    "            model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        conn_fig = visualize_connectivity(connectivity, input_text, target_text)\n",
    "        \n",
    "        # Save the figure\n",
    "        conn_path = os.path.join(output_dir, f\"connectivity_example_{i+1}.png\")\n",
    "        conn_fig.savefig(conn_path)\n",
    "        \n",
    "        if log_to_wandb:\n",
    "            wandb.log({f\"connectivity_example_{i+1}\": wandb.Image(conn_fig)})\n",
    "        \n",
    "        plt.close(conn_fig)\n",
    "    \n",
    "    # 6. Create an interactive version for the last example\n",
    "    if log_to_wandb:\n",
    "        # Create a table with character-by-character connectivity\n",
    "        last_input, last_target = selected_examples[-1]\n",
    "        last_connectivity = compute_connectivity_matrix(\n",
    "            model, encoder_model, tokenizer_src, tokenizer_tgt, last_input, last_target\n",
    "        )\n",
    "        \n",
    "        # Prepare data for interactive table\n",
    "        table_data = []\n",
    "        for i, out_char in enumerate(last_target):\n",
    "            for j, in_char in enumerate(last_input):\n",
    "                table_data.append([\n",
    "                    out_char, in_char, float(last_connectivity[i, j])\n",
    "                ])\n",
    "        \n",
    "        # Create and log W&B table\n",
    "        char_table = wandb.Table(columns=[\"Output Char\", \"Input Char\", \"Connectivity\"], \n",
    "                                data=table_data)\n",
    "        wandb.log({\"character_connectivity\": char_table})\n",
    "    \n",
    "    # Finish W&B run\n",
    "    if log_to_wandb:\n",
    "        wandb.finish()\n",
    "    \n",
    "    print(f\"Connectivity analysis complete. Visualizations saved to {output_dir}\")\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T16:34:58.844869Z",
     "iopub.status.busy": "2025-05-20T16:34:58.844453Z",
     "iopub.status.idle": "2025-05-20T16:34:58.874243Z",
     "shell.execute_reply": "2025-05-20T16:34:58.873398Z",
     "shell.execute_reply.started": "2025-05-20T16:34:58.844850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rnn_visualization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/727373850.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Import the implementation modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# (assuming you've saved the previous code in a module named 'rnn_visualization.py')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from rnn_visualization import (compute_connectivity_matrix, visualize_connectivity, \n\u001b[0m\u001b[1;32m     14\u001b[0m                              \u001b[0mcreate_connectivity_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_connectivity_to_wandb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                              setup_visualization_model, comprehensive_connectivity_analysis)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rnn_visualization'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Import the implementation modules \n",
    "# (assuming you've saved the previous code in a module named 'rnn_visualization.py')\n",
    "from rnn_visualization import (compute_connectivity_matrix, visualize_connectivity, \n",
    "                             create_connectivity_grid, log_connectivity_to_wandb,\n",
    "                             setup_visualization_model, comprehensive_connectivity_analysis)\n",
    "\n",
    "# 1. First, load your trained model and tokenizers\n",
    "# If you've saved your model after training, you can load it:\n",
    "model_path = 'path/to/your/best_model.h5'  # Replace with your model path\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load tokenizers (assuming you've saved them during preprocessing)\n",
    "with open('path/to/your/tokenizer_src.pickle', 'rb') as f:\n",
    "    tokenizer_src = pickle.load(f)\n",
    "    \n",
    "with open('path/to/your/tokenizer_tgt.pickle', 'rb') as f:\n",
    "    tokenizer_tgt = pickle.load(f)\n",
    "\n",
    "# 2. Load or prepare your test data\n",
    "# Option 1: Load from file if you have saved the test data\n",
    "test_data = []\n",
    "with open('path/to/your/test_data.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            latin, devanagari = parts\n",
    "            test_data.append((latin, devanagari))\n",
    "\n",
    "# Option 2: If test data is in another format, convert accordingly\n",
    "# For example, if you have separate lists for inputs and targets:\n",
    "# test_inputs = ['namaste', 'pyaar', 'bharat', ...]\n",
    "# test_targets = ['नमस्ते', 'प्यार', 'भारत', ...]\n",
    "# test_data = list(zip(test_inputs, test_targets))\n",
    "\n",
    "# 3. Initialize W&B for tracking and visualization\n",
    "wandb.init(project=\"DA_seq2seq_transliteration\", name=\"q6-connectivity-visualization\")\n",
    "\n",
    "# 4. Set up visualization models\n",
    "encoder_model, decoder_model = setup_visualization_model(model)\n",
    "\n",
    "# 5. Create a 3x3 grid of connectivity visualizations\n",
    "# Select first 9 examples for the grid\n",
    "selected_examples = test_data[:9]\n",
    "\n",
    "# Create the grid visualization\n",
    "grid_fig = create_connectivity_grid(\n",
    "    model, encoder_model, selected_examples, tokenizer_src, tokenizer_tgt\n",
    ")\n",
    "\n",
    "# Save the grid locally\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "grid_fig.savefig(\"visualizations/connectivity_grid.png\")\n",
    "\n",
    "# Log the grid to W&B\n",
    "wandb.log({\"connectivity_grid\": wandb.Image(grid_fig)})\n",
    "\n",
    "# 6. Analyze individual examples in more detail\n",
    "# For example, let's analyze the first test example\n",
    "example_input, example_target = test_data[0]\n",
    "\n",
    "# Compute the connectivity matrix\n",
    "connectivity = compute_connectivity_matrix(\n",
    "    model, encoder_model, tokenizer_src, tokenizer_tgt, example_input, example_target\n",
    ")\n",
    "\n",
    "# Visualize the connectivity\n",
    "conn_fig = visualize_connectivity(connectivity, example_input, example_target)\n",
    "\n",
    "# Log to W&B\n",
    "wandb.log({\"connectivity_example_1\": wandb.Image(conn_fig)})\n",
    "\n",
    "# 7. Create a table of connectivity statistics for the report\n",
    "stats_data = []\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(selected_examples):\n",
    "    connectivity = compute_connectivity_matrix(\n",
    "        model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "    )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    max_conn = np.max(connectivity)\n",
    "    avg_conn = np.mean(connectivity)\n",
    "    std_conn = np.std(connectivity)\n",
    "    \n",
    "    # Find position of maximum connectivity\n",
    "    max_pos = np.unravel_index(np.argmax(connectivity), connectivity.shape)\n",
    "    max_out_char = target_text[max_pos[0]] if max_pos[0] < len(target_text) else \"N/A\"\n",
    "    max_in_char = input_text[max_pos[1]] if max_pos[1] < len(input_text) else \"N/A\"\n",
    "    \n",
    "    stats_data.append([\n",
    "        input_text, target_text, \n",
    "        float(max_conn), float(avg_conn), float(std_conn),\n",
    "        f\"{max_out_char} (out) <-> {max_in_char} (in)\"\n",
    "    ])\n",
    "\n",
    "# Create and log W&B table\n",
    "columns = [\"Input\", \"Target\", \"Max Connectivity\", \"Avg Connectivity\", \n",
    "          \"Std Connectivity\", \"Max Connection\"]\n",
    "\n",
    "connectivity_table = wandb.Table(columns=columns, data=stats_data)\n",
    "wandb.log({\"connectivity_stats\": connectivity_table})\n",
    "\n",
    "# 8. Find patterns in connectivity\n",
    "# Let's analyze which character positions tend to have the strongest connections\n",
    "\n",
    "# Create matrices to track average connectivity by position\n",
    "max_input_len = max(len(ex[0]) for ex in selected_examples)\n",
    "max_output_len = max(len(ex[1]) for ex in selected_examples)\n",
    "\n",
    "position_counts = np.zeros((max_output_len, max_input_len))\n",
    "position_sums = np.zeros((max_output_len, max_input_len))\n",
    "\n",
    "for input_text, target_text in selected_examples:\n",
    "    connectivity = compute_connectivity_matrix(\n",
    "        model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "    )\n",
    "    \n",
    "    # Add to our position trackers\n",
    "    for i in range(len(target_text)):\n",
    "        for j in range(len(input_text)):\n",
    "            position_sums[i, j] += connectivity[i, j]\n",
    "            position_counts[i, j] += 1\n",
    "\n",
    "# Calculate average connectivity by position (avoid division by zero)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    avg_position_connectivity = np.where(\n",
    "        position_counts > 0, position_sums / position_counts, 0\n",
    "    )\n",
    "\n",
    "# Visualize average connectivity by position\n",
    "pos_fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = sns.heatmap(avg_position_connectivity, cmap='viridis', ax=ax)\n",
    "ax.set_xlabel('Input Character Position')\n",
    "ax.set_ylabel('Output Character Position')\n",
    "ax.set_title('Average Connectivity by Character Position')\n",
    "wandb.log({\"position_connectivity\": wandb.Image(pos_fig)})\n",
    "\n",
    "# 9. Find patterns in the most connected characters\n",
    "# Create a visualization showing which characters tend to be most strongly connected\n",
    "\n",
    "# Dictionary to store character pair connections\n",
    "char_connections = {}\n",
    "\n",
    "for input_text, target_text in selected_examples:\n",
    "    connectivity = compute_connectivity_matrix(\n",
    "        model, encoder_model, tokenizer_src, tokenizer_tgt, input_text, target_text\n",
    "    )\n",
    "    \n",
    "    # For each connection, track strength between character pairs\n",
    "    for i in range(len(target_text)):\n",
    "        out_char = target_text[i]\n",
    "        for j in range(len(input_text)):\n",
    "            in_char = input_text[j]\n",
    "            \n",
    "            # Create a key for this character pair\n",
    "            pair_key = f\"{in_char}->{out_char}\"\n",
    "            \n",
    "            if pair_key not in char_connections:\n",
    "                char_connections[pair_key] = {\n",
    "                    'in_char': in_char,\n",
    "                    'out_char': out_char,\n",
    "                    'total_strength': 0,\n",
    "                    'count': 0\n",
    "                }\n",
    "            \n",
    "            char_connections[pair_key]['total_strength'] += connectivity[i, j]\n",
    "            char_connections[pair_key]['count'] += 1\n",
    "\n",
    "# Calculate average strength for each character pair\n",
    "for pair_key in char_connections:\n",
    "    count = char_connections[pair_key]['count']\n",
    "    if count > 0:\n",
    "        char_connections[pair_key]['avg_strength'] = (\n",
    "            char_connections[pair_key]['total_strength'] / count\n",
    "        )\n",
    "    else:\n",
    "        char_connections[pair_key]['avg_strength'] = 0\n",
    "\n",
    "# Convert to list and sort by strength\n",
    "char_pairs = list(char_connections.values())\n",
    "char_pairs.sort(key=lambda x: x['avg_strength'], reverse=True)\n",
    "\n",
    "# Create and log a table of the strongest character connections\n",
    "if char_pairs:\n",
    "    # Take top 20 connections\n",
    "    top_pairs = char_pairs[:20]\n",
    "    \n",
    "    # Prepare data for table\n",
    "    table_data = [\n",
    "        [p['in_char'], p['out_char'], float(p['avg_strength']), int(p['count'])]\n",
    "        for p in top_pairs\n",
    "    ]\n",
    "    \n",
    "    # Create and log W&B table\n",
    "    pair_table = wandb.Table(\n",
    "        columns=[\"Input Char\", \"Output Char\", \"Avg Strength\", \"Occurrence Count\"],\n",
    "        data=table_data\n",
    "    )\n",
    "    wandb.log({\"strongest_char_connections\": pair_table})\n",
    "\n",
    "# 10. Run a comprehensive analysis that produces all required visualizations\n",
    "comprehensive_connectivity_analysis(\n",
    "    model, test_data, tokenizer_src, tokenizer_tgt, \n",
    "    output_dir=\"connectivity_visualizations\",\n",
    "    log_to_wandb=True\n",
    ")\n",
    "\n",
    "# 11. Finish the W&B run\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Connectivity analysis complete!\")\n",
    "print(\"Check the 'visualizations' and 'connectivity_visualizations' folders for outputs.\")\n",
    "print(\"Additionally, visit your W&B dashboard to see the interactive visualizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7462032,
     "sourceId": 11873693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
