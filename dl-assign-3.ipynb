{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11873693,"sourceType":"datasetVersion","datasetId":7462032}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, GRU, RNN, Dense, Dropout","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:41:20.479096Z","iopub.execute_input":"2025-05-20T05:41:20.479353Z","iopub.status.idle":"2025-05-20T05:41:20.494308Z","shell.execute_reply.started":"2025-05-20T05:41:20.479333Z","shell.execute_reply":"2025-05-20T05:41:20.493574Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T04:58:05.260921Z","iopub.execute_input":"2025-05-20T04:58:05.261552Z","iopub.status.idle":"2025-05-20T04:58:28.146647Z","shell.execute_reply.started":"2025-05-20T04:58:05.261529Z","shell.execute_reply":"2025-05-20T04:58:28.145515Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nCollecting wandb\n  Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nDownloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.9\n    Uninstalling wandb-0.19.9:\n      Successfully uninstalled wandb-0.19.9\nSuccessfully installed wandb-0.19.11\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import wandb\nfrom wandb.integration.keras import WandbCallback\n\nwandb.login(key='e030007b097df00d9a751748294abc8440f932b1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:41:20.495048Z","iopub.execute_input":"2025-05-20T05:41:20.495489Z","iopub.status.idle":"2025-05-20T05:41:20.611845Z","shell.execute_reply.started":"2025-05-20T05:41:20.495460Z","shell.execute_reply":"2025-05-20T05:41:20.611131Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def load_data(file_path):\n    df = pd.read_csv(file_path, sep='\\t', header=None, names=['latin', 'native'])\n    df = df.dropna()\n    df['latin'] = df['latin'].astype(str)\n    df['native'] = df['native'].astype(str)\n    return df\n\ndef load_dakshina_dataset(language_code='hi', base_dir='/kaggle/input/dak-data/dakshina_dataset_v1.0'):\n    path = os.path.join(base_dir, language_code, 'lexicons')\n    return (\n        load_data(os.path.join(path, f'{language_code}.translit.sampled.train.tsv')),\n        load_data(os.path.join(path, f'{language_code}.translit.sampled.dev.tsv')),\n        load_data(os.path.join(path, f'{language_code}.translit.sampled.test.tsv')),\n    )\n\ntrain_data, val_data, test_data = load_dakshina_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:41:20.612880Z","iopub.execute_input":"2025-05-20T05:41:20.613099Z","iopub.status.idle":"2025-05-20T05:41:20.802074Z","shell.execute_reply.started":"2025-05-20T05:41:20.613081Z","shell.execute_reply":"2025-05-20T05:41:20.801332Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Question 1","metadata":{}},{"cell_type":"code","source":"# ─── 1) Extract raw texts ─────────────────────────────────────────\ninput_texts  = train_data['latin'].tolist()\ntarget_texts = ['\\t' + t + '\\n' for t in train_data['native'].tolist()]\n\nval_input_texts  = val_data['latin'].tolist()\nval_target_texts = ['\\t' + t + '\\n' for t in val_data['native'].tolist()]\n\ninput_tokenizer = Tokenizer(char_level=True, oov_token=None)\ninput_tokenizer.fit_on_texts(input_texts + val_input_texts)\n\ntarget_tokenizer = Tokenizer(char_level=True, oov_token=None)\ntarget_tokenizer.fit_on_texts(target_texts + val_target_texts)\n\n# ─── 3) Convert texts → integer sequences + pad to max lengths ───\n# Compute max lengths\nmax_in  = max(len(txt) for txt in input_texts + val_input_texts)\nmax_out = max(len(txt) for txt in target_texts + val_target_texts)\n\n# Integer‑encode + pad\nencoder_input_train = pad_sequences(\n    input_tokenizer.texts_to_sequences(input_texts),\n    maxlen=max_in,\n    padding='post'\n)\ndecoder_input_train = pad_sequences(\n    target_tokenizer.texts_to_sequences(target_texts),\n    maxlen=max_out,\n    padding='post'\n)\n# decoder targets are the decoder inputs shifted left by one\ndecoder_target_train = np.array(decoder_input_train)[:, 1:]\ndecoder_input_train   = np.array(decoder_input_train)[:, :-1]\n\n# Do the same for validation set\nencoder_input_val = pad_sequences(\n    input_tokenizer.texts_to_sequences(val_input_texts),\n    maxlen=max_in,\n    padding='post'\n)\ndecoder_input_val = pad_sequences(\n    target_tokenizer.texts_to_sequences(val_target_texts),\n    maxlen=max_out,\n    padding='post'\n)\ndecoder_target_val = np.array(decoder_input_val)[:, 1:]\ndecoder_input_val   = np.array(decoder_input_val)[:, :-1]\n\n# Make sure any previous wandb runs are finished\ntry:\n    wandb.finish()\nexcept:\n    pass\n\n# Initialize wandb with proper error handling\ntry:\n    wandb.init(\n        project=\"DA_seq2seq_transliteration\",\n        name=\"vanilla_lstm_run_q1\",\n        # Removed reinit=True to prevent connection issues\n        config={\n            \"model_type\": \"vanilla\",\n            \"cell_type\": \"LSTM\",\n            \"embedding_dim\": 64,\n            \"hidden_dim\": 128,\n            \"dropout_rate\": 0.2,\n            \"batch_size\": 64,\n            \"epochs\": 10,\n            \"input_vocab_size\": len(input_tokenizer.word_index) + 1,\n            \"target_vocab_size\": len(target_tokenizer.word_index) + 1,\n            \"max_input_length\": max_in,\n            \"max_target_length\": max_out,\n            \"optimizer\": \"adam\",\n            \"loss\": \"sparse_categorical_crossentropy\",\n            \"dataset\": \"dakshina_hi\"\n        }\n    )\nexcept Exception as e:\n    print(f\"Failed to initialize wandb: {e}\")\n    # Create a dummy wandb to avoid errors in the code\n    class DummyWandb:\n        def log(self, *args, **kwargs):\n            pass\n        def config(self, *args, **kwargs):\n            return type('obj', (object,), {\n                'embedding_dim': 64,\n                'hidden_dim': 128,\n                'get': lambda s, k, d: d\n            })\n    wandb = DummyWandb()\n\nclass VanillaSeq2Seq:\n    def __init__(self,\n                 input_vocab_size,\n                 target_vocab_size,\n                 embedding_dim,\n                 hidden_dim,\n                 cell_type='LSTM',\n                 dropout_rate=0.2,\n                 num_encoder_layers=1,\n                 num_decoder_layers=1):\n        self.input_vocab_size  = input_vocab_size\n        self.target_vocab_size = target_vocab_size\n        self.embedding_dim     = embedding_dim\n        self.hidden_dim        = hidden_dim\n        self.cell_type         = cell_type\n        self.dropout_rate      = dropout_rate\n        self.num_encoder_layers = num_encoder_layers\n        self.num_decoder_layers = num_decoder_layers\n        self.model = self._build_model()\n\n    def _rnn_layer(self, return_sequences, return_state):\n        \"\"\"Factory for one RNN/LSTM/GRU layer.\"\"\"\n        if self.cell_type == 'LSTM':\n            return LSTM(self.hidden_dim,\n                        return_sequences=return_sequences,\n                        return_state=return_state)\n        elif self.cell_type == 'GRU':\n            return GRU(self.hidden_dim,\n                       return_sequences=return_sequences,\n                       return_state=return_state)\n        else:\n            return RNN(self.hidden_dim,\n                       return_sequences=return_sequences,\n                       return_state=return_state)\n\n    def _build_model(self):\n        encoder_inputs = Input(shape=(None,), name='encoder_input')\n        x = Embedding(self.input_vocab_size, self.embedding_dim)(encoder_inputs)\n        x = Dropout(self.dropout_rate)(x)\n\n        # Stack encoder layers\n        encoder_states = []\n        for i in range(self.num_encoder_layers):\n            # last encoder layer returns only state, earlier ones return sequences\n            rs = (i < self.num_encoder_layers - 1)\n            if self.cell_type == 'LSTM':\n                x, state_h, state_c = LSTM(\n                    self.hidden_dim,\n                    return_sequences=rs,\n                    return_state=True,\n                    name=f'enc_lstm_{i}'\n                )(x)\n                encoder_states = [state_h, state_c]\n            else:\n                x, state_h = self._rnn_layer(\n                    return_sequences=rs,\n                    return_state=True\n                )(x)\n                encoder_states = [state_h]\n\n        decoder_inputs = Input(shape=(None,), name='decoder_input')\n        y = Embedding(self.target_vocab_size, self.embedding_dim)(decoder_inputs)\n        y = Dropout(self.dropout_rate)(y)\n\n        # Stack decoder layers\n        for i in range(self.num_decoder_layers):\n            rs = True  # decoder always returns sequences for all but we only care about final dense\n            if self.cell_type == 'LSTM':\n                # feed initial_state only to the first decoder layer\n                init_st = encoder_states if i == 0 else None\n                y, dh, dc = LSTM(\n                    self.hidden_dim,\n                    return_sequences=True,\n                    return_state=True,\n                    name=f'dec_lstm_{i}'\n                )(y, initial_state=init_st) if init_st else LSTM(\n                    self.hidden_dim,\n                    return_sequences=True,\n                    return_state=True,\n                    name=f'dec_lstm_{i}'\n                )(y)\n            else:\n                init_st = encoder_states if i == 0 else None\n                y, dh = self._rnn_layer(\n                    return_sequences=True,\n                    return_state=True\n                )(y, initial_state=init_st) if init_st else self._rnn_layer(\n                    return_sequences=True,\n                    return_state=True\n                )(y)\n\n        # Final projection\n        outputs = Dense(self.target_vocab_size, activation='softmax')(y)\n        return Model([encoder_inputs, decoder_inputs], outputs)\n\n    def compile(self, optimizer='adam', loss='sparse_categorical_crossentropy'):\n        self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\n    def fit(self, train_data, val_data, batch_size=64, epochs=10, callbacks=None):\n        return self.model.fit(\n            [train_data['encoder_input'], train_data['decoder_input']],\n            np.expand_dims(train_data['decoder_target'], -1),\n            validation_data=(\n                [val_data['encoder_input'], val_data['decoder_input']],\n                np.expand_dims(val_data['decoder_target'], -1)\n            ),\n            batch_size=batch_size,\n            epochs=epochs,\n            callbacks=callbacks\n        )\n        \ninput_vocab_size = len(input_tokenizer.word_index) + 1\ntarget_vocab_size = len(target_tokenizer.word_index) + 1\n\nmodel = VanillaSeq2Seq(\n    input_vocab_size=input_vocab_size,\n    target_vocab_size=target_vocab_size,\n    embedding_dim=64,\n    hidden_dim=128,\n    cell_type='LSTM',\n    dropout_rate=0.2\n)\n\nmodel.compile()\n\n# Modified wandb callback with error handling\ntry:\n    wandb_callback = WandbCallback(\n        log_model=False,           # no wandb artifact\n        save_graph=False,          # don't try to render graph\n        save_model=False           # ✅ disables all auto saving\n    )\n    callbacks = [wandb_callback]\nexcept Exception as e:\n    print(f\"Failed to initialize WandbCallback: {e}\")\n    callbacks = []\n\n# Use try-except for wandb config access\ntry:\n    D = wandb.config.embedding_dim\n    H = wandb.config.hidden_dim\n    L_e = wandb.config.get(\"num_encoder_layers\", 1)\n    L_d = wandb.config.get(\"num_decoder_layers\", 1)\nexcept Exception as e:\n    print(f\"Failed to access wandb config: {e}\")\n    D = 64  # Default values\n    H = 128\n    L_e = 1\n    L_d = 1\n\nT_enc = encoder_input_train.shape[1]\nT_dec = decoder_input_train.shape[1]\n\nflops_per_step = 4 * (H * D + H * H)\n\n# 4) Total ops over all layers & timesteps\ntotal_enc_flops = L_e * T_enc * flops_per_step\ntotal_dec_flops = L_d * T_dec * flops_per_step\ntotal_flops = total_enc_flops + total_dec_flops\n\nprint(f\"Approximate total multiplications (encoder + decoder): {total_flops:,}\")\n\ntotal_params = model.model.count_params()\nprint(f\"Total trainable parameters: {total_params:,}\")\n\nmodel.model.summary()\n\nhistory = model.fit(\n    train_data={\n        'encoder_input': encoder_input_train,\n        'decoder_input': decoder_input_train,\n        'decoder_target': decoder_target_train\n    },\n    val_data={\n        'encoder_input': encoder_input_val,\n        'decoder_input': decoder_input_val,\n        'decoder_target': decoder_target_val\n    },\n    batch_size=64,\n    epochs=10,\n    callbacks=callbacks\n)\n\n# Log metrics to wandb with error handling\ntry:\n    wandb.log({\n        \"total_flops\": total_flops,\n        \"total_trainable_params\": total_params\n    })\n    # Properly close the wandb run\n    wandb.finish()\nexcept Exception as e:\n    print(f\"Failed to log to wandb: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:41:29.012847Z","iopub.execute_input":"2025-05-20T05:41:29.013132Z","iopub.status.idle":"2025-05-20T05:45:18.894906Z","shell.execute_reply.started":"2025-05-20T05:41:29.013113Z","shell.execute_reply":"2025-05-20T05:45:18.894096Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_054129-0g3t2u3b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0g3t2u3b' target=\"_blank\">vanilla_lstm_run_q1</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0g3t2u3b' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0g3t2u3b</a>"},"metadata":{}},{"name":"stderr","text":"2025-05-20 05:41:36.847827: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n","output_type":"stream"},{"name":"stdout","text":"Approximate total multiplications (encoder + decoder): 2,260,992\nTotal trainable parameters: 201,869\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ decoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m1,728\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m832\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ enc_lstm_0 (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │         \u001b[38;5;34m98,816\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]     │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dec_lstm_0 (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),    │         \u001b[38;5;34m98,816\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ enc_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],      │\n│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │ enc_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)       │          \u001b[38;5;34m1,677\u001b[0m │ dec_lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ decoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ enc_lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]     │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dec_lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ enc_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],      │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │ enc_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │ dec_lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,869\u001b[0m (788.55 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,869</span> (788.55 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,869\u001b[0m (788.55 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,869</span> (788.55 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.7650 - loss: 0.6321 - val_accuracy: 0.8245 - val_loss: 0.3865\nEpoch 2/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.8265 - loss: 0.3960 - val_accuracy: 0.8294 - val_loss: 0.3805\nEpoch 3/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.8296 - loss: 0.3907 - val_accuracy: 0.8330 - val_loss: 0.3783\nEpoch 4/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8345 - loss: 0.3857 - val_accuracy: 0.8411 - val_loss: 0.3725\nEpoch 5/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8358 - loss: 0.3850 - val_accuracy: 0.8402 - val_loss: 0.3715\nEpoch 6/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8394 - loss: 0.3791 - val_accuracy: 0.8363 - val_loss: 0.3704\nEpoch 7/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8405 - loss: 0.3782 - val_accuracy: 0.8402 - val_loss: 0.3647\nEpoch 8/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.8410 - loss: 0.3738 - val_accuracy: 0.8424 - val_loss: 0.3628\nEpoch 9/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.3718 - val_accuracy: 0.8451 - val_loss: 0.3590\nEpoch 10/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8447 - loss: 0.3682 - val_accuracy: 0.8438 - val_loss: 0.3591\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▁▁▁</td></tr><tr><td>total_flops</td><td>▁</td></tr><tr><td>total_trainable_params</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▇▆▅▆▇██</td></tr><tr><td>val_loss</td><td>█▆▆▄▄▄▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8455</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.35896</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.36751</td></tr><tr><td>total_flops</td><td>2260992</td></tr><tr><td>total_trainable_params</td><td>201869</td></tr><tr><td>val_accuracy</td><td>0.84381</td></tr><tr><td>val_loss</td><td>0.35908</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vanilla_lstm_run_q1</strong> at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0g3t2u3b' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/0g3t2u3b</a><br> View project at: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_054129-0g3t2u3b/logs</code>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, GRU, RNN, Dense, Dropout\nfrom tensorflow.keras.models import Model\nimport os\nimport time\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:55:22.033289Z","iopub.execute_input":"2025-05-20T05:55:22.033606Z","iopub.status.idle":"2025-05-20T05:55:22.038789Z","shell.execute_reply.started":"2025-05-20T05:55:22.033584Z","shell.execute_reply":"2025-05-20T05:55:22.037778Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load the Dakshina dataset (Hindi as an example)\n# You can change 'hi' to the language of your choice\ndef load_dakshina_data(lang='hi'):\n    base_path = f'/kaggle/input/dak-data/dakshina_dataset_v1.0/{lang}/lexicons/'\n    \n    # Load train, dev, test sets\n    train_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.train.tsv', sep='\\t', \n                             header=None, names=['latin', 'native', 'class'])\n    val_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.dev.tsv', sep='\\t', \n                           header=None, names=['latin', 'native', 'class'])\n    test_data = pd.read_csv(f'{base_path}{lang}.translit.sampled.test.tsv', sep='\\t', \n                            header=None, names=['latin', 'native', 'class'])\n\n    # Drop any rows with missing values\n    train_data = train_data.dropna().astype(str)\n    val_data   = val_data.dropna().astype(str)\n    test_data  = test_data.dropna().astype(str)\n\n    return train_data, val_data, test_data\n\n# Process data and create sequences\ndef process_data(train_data, val_data):\n    # Extract texts\n    input_texts = train_data['latin'].tolist()\n    target_texts = ['\\t' + t + '\\n' for t in train_data['native'].tolist()]\n    \n    val_input_texts = val_data['latin'].tolist()\n    val_target_texts = ['\\t' + t + '\\n' for t in val_data['native'].tolist()]\n    \n    # Build character-level tokenizers\n    input_tokenizer = Tokenizer(char_level=True, oov_token=None)\n    input_tokenizer.fit_on_texts(input_texts + val_input_texts)\n    \n    target_tokenizer = Tokenizer(char_level=True, oov_token=None)\n    target_tokenizer.fit_on_texts(target_texts + val_target_texts)\n    \n    # Find max lengths\n    max_in = max(len(txt) for txt in input_texts + val_input_texts)\n    max_out = max(len(txt) for txt in target_texts + val_target_texts)\n    \n    # Convert to sequences and pad\n    encoder_input_train = pad_sequences(\n        input_tokenizer.texts_to_sequences(input_texts),\n        maxlen=max_in,\n        padding='post'\n    )\n    decoder_input_train = pad_sequences(\n        target_tokenizer.texts_to_sequences(target_texts),\n        maxlen=max_out,\n        padding='post'\n    )\n    decoder_target_train = np.array(decoder_input_train)[:, 1:]\n    decoder_input_train = np.array(decoder_input_train)[:, :-1]\n    \n    # Same for validation set\n    encoder_input_val = pad_sequences(\n        input_tokenizer.texts_to_sequences(val_input_texts),\n        maxlen=max_in,\n        padding='post'\n    )\n    decoder_input_val = pad_sequences(\n        target_tokenizer.texts_to_sequences(val_target_texts),\n        maxlen=max_out,\n        padding='post'\n    )\n    decoder_target_val = np.array(decoder_input_val)[:, 1:]\n    decoder_input_val = np.array(decoder_input_val)[:, :-1]\n    \n    return {\n        'input_tokenizer': input_tokenizer,\n        'target_tokenizer': target_tokenizer,\n        'max_in': max_in,\n        'max_out': max_out,\n        'encoder_input_train': encoder_input_train,\n        'decoder_input_train': decoder_input_train,\n        'decoder_target_train': decoder_target_train,\n        'encoder_input_val': encoder_input_val,\n        'decoder_input_val': decoder_input_val,\n        'decoder_target_val': decoder_target_val,\n        'input_texts': input_texts,\n        'target_texts': target_texts,\n        'val_input_texts': val_input_texts,\n        'val_target_texts': val_target_texts\n    }\n\n# Seq2Seq model with configurable parameters\nclass VanillaSeq2Seq:\n    def __init__(self,\n                 input_vocab_size,\n                 target_vocab_size,\n                 embedding_dim,\n                 hidden_dim,\n                 cell_type='LSTM',\n                 dropout_rate=0.2,\n                 num_encoder_layers=1,\n                 num_decoder_layers=1):\n        self.input_vocab_size = input_vocab_size\n        self.target_vocab_size = target_vocab_size\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.cell_type = cell_type\n        self.dropout_rate = dropout_rate\n        self.num_encoder_layers = num_encoder_layers\n        self.num_decoder_layers = num_decoder_layers\n        self.model = self._build_model()\n        \n    def _rnn_layer(self, return_sequences, return_state):\n        \"\"\"Factory for one RNN/LSTM/GRU layer.\"\"\"\n        if self.cell_type == 'LSTM':\n            return LSTM(self.hidden_dim,\n                        return_sequences=return_sequences,\n                        return_state=return_state)\n        elif self.cell_type == 'GRU':\n            return GRU(self.hidden_dim,\n                       return_sequences=return_sequences,\n                       return_state=return_state)\n        else:\n            return RNN(self.hidden_dim,\n                       return_sequences=return_sequences,\n                       return_state=return_state)\n    \n    def _build_model(self):\n        encoder_inputs = Input(shape=(None,), name='encoder_input')\n        x = Embedding(self.input_vocab_size, self.embedding_dim)(encoder_inputs)\n        x = Dropout(self.dropout_rate)(x)\n        \n        # Stack encoder layers\n        encoder_states = []\n        for i in range(self.num_encoder_layers):\n            # last encoder layer returns only state, earlier ones return sequences\n            rs = (i < self.num_encoder_layers - 1)\n            if self.cell_type == 'LSTM':\n                x, state_h, state_c = LSTM(\n                    self.hidden_dim,\n                    return_sequences=rs,\n                    return_state=True,\n                    name=f'enc_lstm_{i}'\n                )(x)\n                encoder_states = [state_h, state_c]\n            else:\n                x, state_h = self._rnn_layer(\n                    return_sequences=rs,\n                    return_state=True\n                )(x)\n                encoder_states = [state_h]\n        \n        decoder_inputs = Input(shape=(None,), name='decoder_input')\n        y = Embedding(self.target_vocab_size, self.embedding_dim)(decoder_inputs)\n        y = Dropout(self.dropout_rate)(y)\n        \n        # Stack decoder layers\n        for i in range(self.num_decoder_layers):\n            rs = True  # decoder always returns sequences\n            if self.cell_type == 'LSTM':\n                # feed initial_state only to the first decoder layer\n                init_st = encoder_states if i == 0 else None\n                y, dh, dc = LSTM(\n                    self.hidden_dim, \n                    return_sequences=True,\n                    return_state=True,\n                    name=f'dec_lstm_{i}'\n                )(y, initial_state=init_st) if init_st else LSTM(\n                    self.hidden_dim,\n                    return_sequences=True,\n                    return_state=True,\n                    name=f'dec_lstm_{i}'\n                )(y)\n            else:\n                init_st = encoder_states if i == 0 else None\n                y, dh = self._rnn_layer(\n                    return_sequences=True,\n                    return_state=True\n                )(y, initial_state=init_st) if init_st else self._rnn_layer(\n                    return_sequences=True,\n                    return_state=True\n                )(y)\n        \n        # Final projection\n        outputs = Dense(self.target_vocab_size, activation='softmax')(y)\n        return Model([encoder_inputs, decoder_inputs], outputs)\n    \n    def compile(self, optimizer='adam', loss='sparse_categorical_crossentropy'):\n        self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n        \n    def fit(self, train_data, val_data, batch_size=64, epochs=10, callbacks=None):\n        return self.model.fit(\n            [train_data['encoder_input'], train_data['decoder_input']],\n            np.expand_dims(train_data['decoder_target'], -1),\n            validation_data=(\n                [val_data['encoder_input'], val_data['decoder_input']],\n                np.expand_dims(val_data['decoder_target'], -1)\n            ),\n            batch_size=batch_size,\n            epochs=epochs,\n            callbacks=callbacks\n        )\n\ndef run_wandb_sweep(processed_data):\n    # Define sweep configuration\n    sweep_config = {\n        'method': 'bayes',\n        'metric': {\n            'name': 'val_accuracy',\n            'goal': 'maximize'\n        },\n        'parameters': {\n            'embedding_dim': {\n                'values': [16, 32, 64, 128]\n            },\n            'hidden_dim': {\n                'values': [32, 64, 128, 256]\n            },\n            'cell_type': {\n                'values': ['RNN', 'GRU', 'LSTM']\n            },\n            'dropout_rate': {\n                'values': [0.1, 0.2, 0.3]\n            },\n            'num_encoder_layers': {\n                'values': [1, 2]\n            },\n            'num_decoder_layers': {\n                'values': [1, 2]\n            }\n        }\n    }\n    \n    # Initialize sweep\n    sweep_id = wandb.sweep(sweep_config, project=\"DA_seq2seq_transliteration\")\n    \n    # Define the training function\n    def train_model():\n        # Make sure we're in a clean wandb state\n        try:\n            wandb.finish()\n        except:\n            pass\n        \n        # Start a new wandb run\n        run = wandb.init()\n        \n        # Access hyperparameters from wandb\n        config = wandb.config\n        \n        # Create model with hyperparameters from wandb\n        input_vocab_size = len(processed_data['input_tokenizer'].word_index) + 1\n        target_vocab_size = len(processed_data['target_tokenizer'].word_index) + 1\n        \n        model = VanillaSeq2Seq(\n            input_vocab_size=input_vocab_size,\n            target_vocab_size=target_vocab_size,\n            embedding_dim=config.embedding_dim,\n            hidden_dim=config.hidden_dim,\n            cell_type=config.cell_type,\n            dropout_rate=config.dropout_rate,\n            num_encoder_layers=config.num_encoder_layers,\n            num_decoder_layers=config.num_decoder_layers\n        )\n        \n        model.compile()\n        \n        # Configure wandb callback\n        wandb_callback = WandbCallback(\n            log_model=False,\n            save_graph=False,\n            save_model=False\n        )\n        \n        # Compute model complexity metrics\n        D = config.embedding_dim\n        H = config.hidden_dim\n        L_e = config.num_encoder_layers\n        L_d = config.num_decoder_layers\n        T_enc = processed_data['encoder_input_train'].shape[1]\n        T_dec = processed_data['decoder_input_train'].shape[1]\n        \n        flops_per_step = 4 * (H * D + H * H)\n        total_enc_flops = L_e * T_enc * flops_per_step\n        total_dec_flops = L_d * T_dec * flops_per_step\n        total_flops = total_enc_flops + total_dec_flops\n        \n        total_params = model.model.count_params()\n        \n        print(f\"Embedding dim: {D}, Hidden dim: {H}\")\n        print(f\"Encoder layers: {L_e}, Decoder layers: {L_d}\")\n        print(f\"Cell type: {config.cell_type}, Dropout: {config.dropout_rate}\")\n        print(f\"Total parameters: {total_params:,}\")\n        print(f\"Total FLOPs: {total_flops:,}\")\n        \n        # Log model complexity metrics\n        wandb.log({\n            \"total_flops\": total_flops,\n            \"total_params\": total_params\n        })\n        \n        # Train the model\n        start_time = time.time()\n        \n        history = model.fit(\n            train_data={\n                'encoder_input': processed_data['encoder_input_train'],\n                'decoder_input': processed_data['decoder_input_train'],\n                'decoder_target': processed_data['decoder_target_train']\n            },\n            val_data={\n                'encoder_input': processed_data['encoder_input_val'],\n                'decoder_input': processed_data['decoder_input_val'],\n                'decoder_target': processed_data['decoder_target_val']\n            },\n            batch_size=64,\n            epochs=10,\n            callbacks=[wandb_callback]\n        )\n        \n        training_time = time.time() - start_time\n        \n        # Log additional metrics\n        wandb.log({\n            \"training_time\": training_time,\n            \"final_train_accuracy\": history.history['accuracy'][-1],\n            \"final_val_accuracy\": history.history['val_accuracy'][-1]\n        })\n        \n        # Clean up (important to avoid memory leaks)\n        tf.keras.backend.clear_session()\n        run.finish()\n    \n    # Run the sweep\n    wandb.agent(sweep_id, train_model, count=3)  # Adjust count based on time constraints\n\n# Main execution\nif __name__ == \"__main__\":\n    # Ensure TensorFlow doesn't reserve all GPU memory\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    \n    # Load data\n    try:\n        train_data, val_data, test_data = load_dakshina_data(lang='hi')\n        print(f\"Data loaded successfully! Train size: {len(train_data)}\")\n        \n        # Process data\n        processed_data = process_data(train_data, val_data)\n        print(\"Data processed successfully!\")\n        \n        # Run sweep\n        print(\"Starting hyperparameter sweep...\")\n        run_wandb_sweep(processed_data)\n        \n    except Exception as e:\n        print(f\"Error: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:55:24.828043Z","iopub.execute_input":"2025-05-20T05:55:24.829162Z"}},"outputs":[{"name":"stdout","text":"Data loaded successfully! Train size: 44202\nData processed successfully!\nStarting hyperparameter sweep...\nCreate sweep with ID: qoxu1z5h\nSweep URL: https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/qoxu1z5h\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tr1ifgs3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_055533-tr1ifgs3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/tr1ifgs3' target=\"_blank\">vocal-sweep-1</a></strong> to <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/qoxu1z5h' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/qoxu1z5h</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/qoxu1z5h' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/sweeps/qoxu1z5h</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/tr1ifgs3' target=\"_blank\">https://wandb.ai/mm21b044-indian-institute-of-technology-madras/DA_seq2seq_transliteration/runs/tr1ifgs3</a>"},"metadata":{}},{"name":"stdout","text":"Embedding dim: 128, Hidden dim: 32\nEncoder layers: 1, Decoder layers: 1\nCell type: GRU, Dropout: 0.3\nTotal parameters: 43,965\nTotal FLOPs: 819,200\nEpoch 1/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.6977 - loss: 1.2141 - val_accuracy: 0.7457 - val_loss: 0.8501\nEpoch 2/10\n\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.7442 - loss: 0.8595 - val_accuracy: 0.7710 - val_loss: 0.7643\nEpoch 3/10\n\u001b[1m409/691\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.7614 - loss: 0.7994","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}